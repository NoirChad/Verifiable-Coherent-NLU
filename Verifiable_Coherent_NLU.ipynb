{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL9AU7zTgP9n"
      },
      "source": [
        "### **Toward Consistent, Verifiable, and Coherent Commonsense Reasoning in Large LMs**\n",
        "\n",
        "This notebook provides source code for our two papers in Findings of EMNLP 2021:\n",
        "\n",
        "\n",
        "1.  Shane Storks, Qiaozi Gao, Yichi Zhang, and Joyce Y. Chai (2021). *Tiered Reasoning for Intuitive Physics: Toward Verifiable Commonsense Language Understanding.* Findings of EMNLP 2021.\n",
        "2.   Shane Storks and Joyce Y. Chai (2021). *Beyond the Tip of the Iceberg: Assessing Coherence of Text Classifiers.* Findings of EMNLP 2021.\n",
        "\n",
        "*If you have any questions or problems, please open an issue on our [GitHub repo](https://github.com/sled-group/Verifiable-Coherent-NLU) or email Shane Storks.*\n",
        "\n",
        "***First, configure the execution mode by selecting a few settings (expand cell if needed):***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct4cd2_TFYDk"
      },
      "source": [
        "   0. (Colab only) Insert the path in your Google Drive to the folder where this notebook is located."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq9-dXJXFWh3"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/NoirChad/Verifiable-Coherent-NLU.git\n",
        "DRIVE_PATH = 'Verifiable-Coherent-NLU'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxzL0hhHAHzN"
      },
      "source": [
        "1.   Model type (choose from BERT large, RoBERTa large, RoBERTa large + MNLI, DeBERTa base, and DeBERTa large).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFNe6vlTaHsP"
      },
      "outputs": [],
      "source": [
        "# mode = 'bert' # BERT large\n",
        "# mode = 'roberta' # RoBERTa large\n",
        "# mode = 'roberta_mnli' # RoBERTa large pre-trained on MNLI\n",
        "# mode = 'deberta' # DeBERTa base for training on TRIP\n",
        "# mode = 'deberta_large' # DeBERTa large for training on CE and ART\n",
        "mode = 'XLNet'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJ-XeY1aCpD"
      },
      "source": [
        "2.   Name of the task we want to train or evaluate on. Set `debug` to `True` to run quick training/evaluation jobs on only a small amount of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAQGu6JMa-o6"
      },
      "outputs": [],
      "source": [
        "task_name = 'trip'\n",
        "# task_name = 'ce'\n",
        "# task_name = 'art'\n",
        "\n",
        "debug = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoWKXfQBd435"
      },
      "source": [
        "3.   (If training models) Training batch size, learning rate, and maximum number of epochs. Settings for results in the paper are provided as examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyFFcZtkeKwT"
      },
      "outputs": [],
      "source": [
        "config_batch_size = 16\n",
        "config_lr = 1e-5 # Selected learning rate for best RoBERTa-based model in TRIP paper\n",
        "config_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH9a70CTaGpG"
      },
      "source": [
        "4.   (For training TRIP models only) Configure the loss weighting scheme for training models here. We provide the 4 modes from the paper as examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvQEiNBSACak"
      },
      "outputs": [],
      "source": [
        "# Loss weights for (attributes, preconditions, effects, conflicts, story choices)\n",
        "if task_name != 'trip':\n",
        "  print(\"We do not need a loss weighting scheme for %s dataset. Ignoring this cell.\" % task_name)\n",
        "loss_weights = [0.0, 0.4, 0.4, 0.1, 0.1] # \"All losses\"\n",
        "# loss_weights = [0.0, 0.4, 0.4, 0.2, 0.0] # \"Omit story choice loss\"\n",
        "# loss_weights = [0.0, 0.4, 0.4, 0.0, 0.2] # \"Omit conflict detection loss\"\n",
        "# loss_weights = [0.0, 0.0, 0.0, 0.5, 0.5] # \"Omit state classification losses\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmpchQTIg3HZ"
      },
      "source": [
        "   5. (If evaluating models) Provide the name of the pre-trained model directory here. This should be the name of a directory within the *saved_models* directory, which should be located where this notebook is. Names of provided pre-trained model directories are listed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8tH7UMZhI1N"
      },
      "outputs": [],
      "source": [
        "# TRIP, all losses\n",
        "# eval_model_dir = 'bert-large-uncased_cloze_1_5e-06_4_0.0-0.4-0.4-0.1-0.1_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'roberta-large_cloze_1_1e-05_7_0.0-0.4-0.4-0.1-0.1_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'microsoft-deberta-base_cloze_1_5e-06_5_0.0-0.4-0.4-0.1-0.1_tiered_pipeline_ablate_attributes_states-logits'\n",
        "\n",
        "# TRIP, no story classification loss\n",
        "# eval_model_dir = 'bert-large-uncased_cloze_1_5e-05_8_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'roberta-large_cloze_1_1e-05_5_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_lc_ablate_attributes_states-logits' # Best model trained in the TRIP paper\n",
        "# eval_model_dir = 'microsoft-deberta-base_cloze_1_5e-05_5_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_ablate_attributes_states-logits'\n",
        "\n",
        "# TRIP, no conflict detection loss\n",
        "# eval_model_dir = 'bert-large-uncased_cloze_1_1e-06_1_0.0-0.4-0.4-0.0-0.2_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'roberta-large_cloze_1_5e-06_8_0.0-0.4-0.4-0.0-0.2_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'microsoft-deberta-base_cloze_1_1e-06_3_0.0-0.4-0.4-0.0-0.2_tiered_pipeline_ablate_attributes_states-logits'\n",
        "\n",
        "# TRIP, no physical state classification loss\n",
        "# eval_model_dir = 'bert-large-uncased_cloze_1_1e-05_3_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'roberta-large_cloze_1_1e-06_7_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_ablate_attributes_states-logits'\n",
        "# eval_model_dir = 'microsoft-deberta-base_cloze_1_5e-06_9_0.0-0.0-0.0-0.5-0.5_tiered_pipeline_ablate_attributes_states-logits'\n",
        "\n",
        "# CE\n",
        "# eval_model_dir = 'bert-large-uncased_ConvEnt_32_7.5e-06_7_xval'\n",
        "# eval_model_dir = 'roberta-large_ConvEnt_32_7.5e-06_9_xval'\n",
        "# eval_model_dir = 'roberta-large-mnli_ConvEnt_32_7.5e-06_7_xval'\n",
        "# eval_model_dir = 'microsoft-deberta-large_ConvEnt_16_1e-05_9_xval'\n",
        "\n",
        "# ART\n",
        "# eval_model_dir = 'bert-large-uncased_art_64_5e-06_8'\n",
        "# eval_model_dir = 'roberta-large_art_64_2.5e-06_4'\n",
        "# eval_model_dir = 'DeBERTa-deberta-large_art_32_1e-06_8'\n",
        "\n",
        "#TRIP, XLNet\n",
        "eval_model_dir = 'xlnet-base-cased_cloze_4_1e-05_15_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_lc_ablate_attributes_states-logits'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GA5VS3Sfgfz"
      },
      "source": [
        "**For more configuration options, scroll down to the Train Models > Configure Hyperparameters cell for the task you're working on.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqJWG4SAK4Um",
        "outputId": "04a207b4-3ee7-49af-c868-295e568df579"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqvj34KhLL0k"
      },
      "source": [
        "# Setup\n",
        "Run this block every time when starting up the notebook. It will get Colab ready, preprocess the data, and load model packages and classes we'll need later. May take several minutes to run for the first time.\n",
        "\n",
        "**If you get a `ModuleNotFoundError` for the `www` code base, try the following:**\n",
        "\n",
        "\n",
        "1.   Ensure the DRIVE_PATH is set properly above.\n",
        "2.   (Colab only) Verify that this notebook has access to your Google Drive (click the folder icon on the left and then the Google Drive icon).\n",
        "2.   Try to restart the runtime and refresh your browser window.\n",
        "2.   (Colab only) If the problem persists, revoke access to Google Drive and re-enable it.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm7qzKnAnbU9"
      },
      "source": [
        "## Colab Setup\n",
        "\n",
        "Enable auto reloading of code libraries from Google Drive, set up connection to Google Drive, and import some packages. ðŸ”Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8h8hUVaqySd"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3dNQeNNnkHD",
        "outputId": "4fbd07bf-7270-4116-e05e-aa447d5d28ee"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.2.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import spacy\n",
        "!pip install jsonlines\n",
        "\n",
        "sys.path.append(DRIVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQLB_Y-wSsfk"
      },
      "source": [
        "## Model Setup\n",
        "\n",
        "Next, we'll load up the transformer model, tokenizer, etc. â³"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoY37xIF-oP7"
      },
      "source": [
        "### Install HuggingFace transformers and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rp3vUVjT9I4",
        "outputId": "8580220d-5eee-40df-f389-efe09fec24de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.2.2 in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (4.62.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (0.0.46)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (0.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.2) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.2) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.2) (3.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torchvision==0.8.2 in /usr/local/lib/python3.7/dist-packages (0.8.2)\n",
            "Requirement already satisfied: torchaudio==0.7.2 in /usr/local/lib/python3.7/dist-packages (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install 'transformers==4.2.2'\n",
        "!pip install sentencepiece\n",
        "!pip3 install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2\n",
        "# !pip install deberta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4LFuLhzAa2j"
      },
      "source": [
        "### Get Model Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZhhgV9c__TU"
      },
      "source": [
        "Specify which model parameters from transformers we want to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA6XunCb_gd9"
      },
      "outputs": [],
      "source": [
        "if task_name in ['trip', 'ce']:\n",
        "  multiple_choice = False\n",
        "elif task_name == 'art':\n",
        "  multiple_choice = True\n",
        "else:\n",
        "  raise ValueError(\"Task name should be set to 'trip', 'ce', or 'art' in the first cell of the notebook!\")\n",
        "\n",
        "if mode == 'bert':\n",
        "  model_name = 'bert-large-uncased'\n",
        "elif mode == 'roberta':\n",
        "  model_name = 'roberta-large'\n",
        "elif mode == 'roberta_mnli':\n",
        "  model_name = 'roberta-large-mnli'\n",
        "elif mode == 'deberta':\n",
        "  model_name = 'microsoft/deberta-base'\n",
        "elif mode == 'deberta_large':\n",
        "  model_name = 'microsoft/deberta-large'\n",
        "elif mode == 'XLNet':\n",
        "  model_name = 'xlnet-base-cased'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgFIl1MJ-185"
      },
      "source": [
        "Load the tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etkxf75f-9Gj"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, RobertaTokenizer, DebertaTokenizer, AlbertTokenizer, T5Tokenizer, GPT2Tokenizer,XLNetTokenizer\n",
        "\n",
        "# from DeBERTa import deberta\n",
        "if mode in ['bert']:\n",
        "  tokenizer_class = BertTokenizer\n",
        "elif mode in ['roberta', 'roberta_mnli']:\n",
        "  tokenizer_class = RobertaTokenizer\n",
        "elif mode in ['deberta', 'deberta_large']:\n",
        "  tokenizer_class = DebertaTokenizer\n",
        "elif mode in ['XLNet']:\n",
        "  tokenizer_class = XLNetTokenizer\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(model_name, \n",
        "                                                do_lower_case = False, \n",
        "                                                cache_dir=os.path.join(DRIVE_PATH, 'cache'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0iYZG6bBGIf"
      },
      "source": [
        "Load the model and optimizer:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PxFghcDBPm_"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, RobertaForSequenceClassification, DebertaForSequenceClassification, AlbertForSequenceClassification, AdamW\n",
        "from transformers import BertForMultipleChoice, RobertaForMultipleChoice, AlbertForMultipleChoice, DebertaModel\n",
        "from transformers import BertModel, RobertaModel, AlbertModel, DebertaModel, T5Model, T5EncoderModel, GPT2Model\n",
        "from transformers import RobertaForMaskedLM\n",
        "from transformers import BertConfig, RobertaConfig, DebertaConfig, AlbertConfig, T5Config, GPT2Config\n",
        "from transformers import XLNetConfig, XLNetModel, XLNetForSequenceClassification, XLNetForMultipleChoice\n",
        "from www.model.transformers_ext import DebertaForMultipleChoice\n",
        "from torch.optim import Adam\n",
        "if not multiple_choice:\n",
        "  if mode == 'bert':\n",
        "    model_class = BertForSequenceClassification\n",
        "    config_class = BertConfig\n",
        "    emb_class = BertModel\n",
        "  elif mode in ['roberta', 'roberta_mnli']:\n",
        "    model_class = RobertaForSequenceClassification\n",
        "    config_class = RobertaConfig\n",
        "    emb_class = RobertaModel\n",
        "    lm_class = RobertaForMaskedLM\n",
        "  elif mode in ['deberta', 'deberta_large']:\n",
        "    model_class = DebertaForSequenceClassification\n",
        "    config_class = DebertaConfig\n",
        "    emb_class = DebertaModel\n",
        "  elif mode in ['XLNet']:\n",
        "    model_class = XLNetForSequenceClassification\n",
        "    config_class = XLNetConfig\n",
        "    emb_class = XLNetModel\n",
        "else:\n",
        "  if mode == 'bert':\n",
        "    model_class = BertForMultipleChoice\n",
        "    config_class = BertConfig\n",
        "    emb_class = BertModel    \n",
        "  elif mode in ['roberta', 'roberta_mnli']:\n",
        "    model_class = RobertaForMultipleChoice\n",
        "    config_class = RobertaConfig\n",
        "    emb_class = RobertaModel\n",
        "    lm_class = RobertaForMaskedLM\n",
        "  elif mode in ['deberta', 'deberta_large']:\n",
        "    model_class = DebertaForMultipleChoice\n",
        "    config_class = DebertaConfig\n",
        "    emb_class = DebertaModel\n",
        "  elif mode in ['XLNet']:\n",
        "    model_class = XLNetForMultipleChoice\n",
        "    config_class = XLNetConfig\n",
        "    emb_class = XLNetModel\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzFnAVtuUmpQ"
      },
      "source": [
        "## Data Setup\n",
        "\n",
        "Preprocess the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKY0hTEgnQgB"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Construct the dataset from the .txt files collected from AMT. Save a backup copy in Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE-LOkJ4nWuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86321c9-d6ba-4aeb-acc4-616998bf6eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed examples:\n",
            "{\n",
            "  story_id: \n",
            "    13,\n",
            "  worker_id: \n",
            "    A32W24TWSWXW,\n",
            "  type: \n",
            "    None,\n",
            "  idx: \n",
            "    None,\n",
            "  aug: \n",
            "    False,\n",
            "  actor: \n",
            "    John,\n",
            "  location: \n",
            "    kitchen,\n",
            "  objects: \n",
            "    cabinet, counter, knife, pan, potato, pizza,\n",
            "  sentences: \n",
            "    [\n",
            "      John was getting the snacks ready for the party.\n",
            "      John opened the cabinet, took out a pan and put it on the counter.\n",
            "      John opened the fridge and got out the pizza.\n",
            "      John put the pizza on the pan and put them into the oven.\n",
            "      John took a knife and cut the hot pizza in eight slices.\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  example_id: \n",
            "    13,\n",
            "  plausible: \n",
            "    True,\n",
            "  breakpoint: \n",
            "    -1,\n",
            "  confl_sents: \n",
            "    [],\n",
            "  confl_pairs: \n",
            "    [],\n",
            "  states: \n",
            "    [\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['snacks', 0], ['party', 0]], 'exist': [['snacks', 4], ['party', 2]], 'clean': [['snacks', 0], ['party', 0]], 'power': [['snacks', 0], ['party', 0]], 'functional': [['snacks', 2], ['party', 2]], 'pieces': [['snacks', 0], ['party', 0]], 'wet': [['snacks', 0], ['party', 0]], 'open': [['snacks', 0], ['party', 0]], 'temperature': [['snacks', 0], ['party', 0]], 'solid': [['snacks', 0], ['party', 0]], 'contain': [['snacks', 0], ['party', 0]], 'running': [['snacks', 0], ['party', 0]], 'moveable': [['snacks', 2], ['party', 2]], 'mixed': [['snacks', 0], ['party', 0]], 'edible': [['snacks', 0], ['party', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['counter', 0], ['pan', 7], ['cabinet', 0]], 'exist': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'clean': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'power': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'functional': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'pieces': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'wet': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'open': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'temperature': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'solid': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'contain': [['counter', 6], ['pan', 0], ['cabinet', 8]], 'running': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'moveable': [['counter', 0], ['pan', 2], ['cabinet', 0]], 'mixed': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'edible': [['counter', 0], ['pan', 0], ['cabinet', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['fridge', 0], ['pizza', 7]], 'exist': [['fridge', 2], ['pizza', 2]], 'clean': [['fridge', 0], ['pizza', 0]], 'power': [['fridge', 2], ['pizza', 0]], 'functional': [['fridge', 2], ['pizza', 2]], 'pieces': [['fridge', 0], ['pizza', 0]], 'wet': [['fridge', 0], ['pizza', 0]], 'open': [['fridge', 4], ['pizza', 0]], 'temperature': [['fridge', 0], ['pizza', 1]], 'solid': [['fridge', 0], ['pizza', 0]], 'contain': [['fridge', 8], ['pizza', 0]], 'running': [['fridge', 2], ['pizza', 0]], 'moveable': [['fridge', 2], ['pizza', 2]], 'mixed': [['fridge', 0], ['pizza', 0]], 'edible': [['fridge', 0], ['pizza', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['oven', 0], ['pizza', 3], ['pan', 6]], 'exist': [['oven', 2], ['pizza', 2], ['pan', 2]], 'clean': [['oven', 0], ['pizza', 0], ['pan', 0]], 'power': [['oven', 2], ['pizza', 0], ['pan', 0]], 'functional': [['oven', 2], ['pizza', 2], ['pan', 2]], 'pieces': [['oven', 0], ['pizza', 0], ['pan', 0]], 'wet': [['oven', 0], ['pizza', 0], ['pan', 0]], 'open': [['oven', 8], ['pizza', 0], ['pan', 0]], 'temperature': [['oven', 2], ['pizza', 0], ['pan', 0]], 'solid': [['oven', 0], ['pizza', 0], ['pan', 0]], 'contain': [['oven', 6], ['pizza', 0], ['pan', 4]], 'running': [['oven', 0], ['pizza', 0], ['pan', 0]], 'moveable': [['oven', 0], ['pizza', 2], ['pan', 2]], 'mixed': [['oven', 0], ['pizza', 0], ['pan', 0]], 'edible': [['oven', 0], ['pizza', 0], ['pan', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['knife', 2], ['slices', 2], ['hot pizza', 0]], 'exist': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'clean': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'power': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'functional': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'pieces': [['knife', 0], ['slices', 0], ['hot pizza', 4]], 'wet': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'open': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'temperature': [['knife', 0], ['slices', 0], ['hot pizza', 2]], 'solid': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'contain': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'running': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'moveable': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'mixed': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'edible': [['knife', 0], ['slices', 0], ['hot pizza', 0]]}\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n",
            "{\n",
            "  story_id: \n",
            "    13,\n",
            "  worker_id: \n",
            "    A32W24TWSWXW,\n",
            "  type: \n",
            "    cloze,\n",
            "  idx: \n",
            "    0,\n",
            "  aug: \n",
            "    False,\n",
            "  actor: \n",
            "    John,\n",
            "  location: \n",
            "    kitchen,\n",
            "  objects: \n",
            "    cabinet, counter, knife, pan, potato, pizza,\n",
            "  sentences: \n",
            "    [\n",
            "      John was getting the snacks ready for the party.\n",
            "      John opened the cabinet, took out a pan and put it on the counter.\n",
            "      John opened the fridge and got out the pizza.\n",
            "      John put the pizza on the pan and put them into the oven.\n",
            "      John called the pizza joint to deliver a pizza.\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  example_id: \n",
            "    13-C0,\n",
            "  plausible: \n",
            "    False,\n",
            "  breakpoint: \n",
            "    4,\n",
            "  confl_sents: \n",
            "    [\n",
            "      2\n",
            "      3\n",
            "    ],\n",
            "  confl_pairs: \n",
            "    [\n",
            "      [2, 4]\n",
            "      [3, 4]\n",
            "    ],\n",
            "  states: \n",
            "    [\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['snacks', 0], ['party', 0]], 'exist': [['snacks', 4], ['party', 2]], 'clean': [['snacks', 0], ['party', 0]], 'power': [['snacks', 0], ['party', 0]], 'functional': [['snacks', 2], ['party', 2]], 'pieces': [['snacks', 0], ['party', 0]], 'wet': [['snacks', 0], ['party', 0]], 'open': [['snacks', 0], ['party', 0]], 'temperature': [['snacks', 0], ['party', 0]], 'solid': [['snacks', 0], ['party', 0]], 'contain': [['snacks', 0], ['party', 0]], 'running': [['snacks', 0], ['party', 0]], 'moveable': [['snacks', 2], ['party', 2]], 'mixed': [['snacks', 0], ['party', 0]], 'edible': [['snacks', 0], ['party', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['counter', 0], ['pan', 7], ['cabinet', 0]], 'exist': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'clean': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'power': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'functional': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'pieces': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'wet': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'open': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'temperature': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'solid': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'contain': [['counter', 6], ['pan', 0], ['cabinet', 8]], 'running': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'moveable': [['counter', 0], ['pan', 2], ['cabinet', 0]], 'mixed': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'edible': [['counter', 0], ['pan', 0], ['cabinet', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['fridge', 0], ['pizza', 7]], 'exist': [['fridge', 2], ['pizza', 2]], 'clean': [['fridge', 0], ['pizza', 0]], 'power': [['fridge', 2], ['pizza', 0]], 'functional': [['fridge', 2], ['pizza', 2]], 'pieces': [['fridge', 0], ['pizza', 0]], 'wet': [['fridge', 0], ['pizza', 0]], 'open': [['fridge', 4], ['pizza', 0]], 'temperature': [['fridge', 0], ['pizza', 1]], 'solid': [['fridge', 0], ['pizza', 0]], 'contain': [['fridge', 8], ['pizza', 0]], 'running': [['fridge', 2], ['pizza', 0]], 'moveable': [['fridge', 2], ['pizza', 2]], 'mixed': [['fridge', 0], ['pizza', 0]], 'edible': [['fridge', 0], ['pizza', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['oven', 0], ['pizza', 3], ['pan', 6]], 'exist': [['oven', 2], ['pizza', 2], ['pan', 2]], 'clean': [['oven', 0], ['pizza', 0], ['pan', 0]], 'power': [['oven', 2], ['pizza', 0], ['pan', 0]], 'functional': [['oven', 2], ['pizza', 2], ['pan', 2]], 'pieces': [['oven', 0], ['pizza', 0], ['pan', 0]], 'wet': [['oven', 0], ['pizza', 0], ['pan', 0]], 'open': [['oven', 8], ['pizza', 0], ['pan', 0]], 'temperature': [['oven', 2], ['pizza', 0], ['pan', 0]], 'solid': [['oven', 0], ['pizza', 0], ['pan', 0]], 'contain': [['oven', 6], ['pizza', 0], ['pan', 4]], 'running': [['oven', 0], ['pizza', 0], ['pan', 0]], 'moveable': [['oven', 0], ['pizza', 2], ['pan', 2]], 'mixed': [['oven', 0], ['pizza', 0], ['pan', 0]], 'edible': [['oven', 0], ['pizza', 0], ['pan', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['pizza', 0]], 'exist': [['pizza', 4]], 'clean': [['pizza', 0]], 'power': [['pizza', 0]], 'functional': [['pizza', 2]], 'pieces': [['pizza', 0]], 'wet': [['pizza', 0]], 'open': [['pizza', 0]], 'temperature': [['pizza', 0]], 'solid': [['pizza', 0]], 'contain': [['pizza', 0]], 'running': [['pizza', 0]], 'moveable': [['pizza', 2]], 'mixed': [['pizza', 0]], 'edible': [['pizza', 0]]}\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n",
            "{\n",
            "  story_id: \n",
            "    13,\n",
            "  worker_id: \n",
            "    A32W24TWSWXW,\n",
            "  type: \n",
            "    order,\n",
            "  idx: \n",
            "    2,\n",
            "  aug: \n",
            "    False,\n",
            "  actor: \n",
            "    John,\n",
            "  location: \n",
            "    kitchen,\n",
            "  objects: \n",
            "    cabinet, counter, knife, pan, potato, pizza,\n",
            "  sentences: \n",
            "    [\n",
            "      John was getting the snacks ready for the party.\n",
            "      John opened the cabinet, took out a pan and put it on the counter.\n",
            "      John put the pizza on the pan and put them into the oven.\n",
            "      John opened the fridge and got out the pizza.\n",
            "      John took a knife and cut the hot pizza in eight slices.\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  example_id: \n",
            "    13-O2,\n",
            "  plausible: \n",
            "    False,\n",
            "  breakpoint: \n",
            "    3,\n",
            "  confl_sents: \n",
            "    [\n",
            "      2\n",
            "    ],\n",
            "  confl_pairs: \n",
            "    [],\n",
            "  states: \n",
            "    [\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['snacks', 0], ['party', 0]], 'exist': [['snacks', 4], ['party', 2]], 'clean': [['snacks', 0], ['party', 0]], 'power': [['snacks', 0], ['party', 0]], 'functional': [['snacks', 2], ['party', 2]], 'pieces': [['snacks', 0], ['party', 0]], 'wet': [['snacks', 0], ['party', 0]], 'open': [['snacks', 0], ['party', 0]], 'temperature': [['snacks', 0], ['party', 0]], 'solid': [['snacks', 0], ['party', 0]], 'contain': [['snacks', 0], ['party', 0]], 'running': [['snacks', 0], ['party', 0]], 'moveable': [['snacks', 2], ['party', 2]], 'mixed': [['snacks', 0], ['party', 0]], 'edible': [['snacks', 0], ['party', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['counter', 0], ['pan', 7], ['cabinet', 0]], 'exist': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'clean': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'power': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'functional': [['counter', 2], ['pan', 2], ['cabinet', 2]], 'pieces': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'wet': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'open': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'temperature': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'solid': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'contain': [['counter', 6], ['pan', 0], ['cabinet', 8]], 'running': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'moveable': [['counter', 0], ['pan', 2], ['cabinet', 0]], 'mixed': [['counter', 0], ['pan', 0], ['cabinet', 0]], 'edible': [['counter', 0], ['pan', 0], ['cabinet', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['oven', 0], ['pizza', 3], ['pan', 6]], 'exist': [['oven', 2], ['pizza', 2], ['pan', 2]], 'clean': [['oven', 0], ['pizza', 0], ['pan', 0]], 'power': [['oven', 2], ['pizza', 0], ['pan', 0]], 'functional': [['oven', 2], ['pizza', 2], ['pan', 2]], 'pieces': [['oven', 0], ['pizza', 0], ['pan', 0]], 'wet': [['oven', 0], ['pizza', 0], ['pan', 0]], 'open': [['oven', 8], ['pizza', 0], ['pan', 0]], 'temperature': [['oven', 2], ['pizza', 0], ['pan', 0]], 'solid': [['oven', 0], ['pizza', 0], ['pan', 0]], 'contain': [['oven', 6], ['pizza', 0], ['pan', 4]], 'running': [['oven', 0], ['pizza', 0], ['pan', 0]], 'moveable': [['oven', 0], ['pizza', 2], ['pan', 2]], 'mixed': [['oven', 0], ['pizza', 0], ['pan', 0]], 'edible': [['oven', 0], ['pizza', 0], ['pan', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['fridge', 0], ['pizza', 7]], 'exist': [['fridge', 2], ['pizza', 2]], 'clean': [['fridge', 0], ['pizza', 0]], 'power': [['fridge', 2], ['pizza', 0]], 'functional': [['fridge', 2], ['pizza', 2]], 'pieces': [['fridge', 0], ['pizza', 0]], 'wet': [['fridge', 0], ['pizza', 0]], 'open': [['fridge', 4], ['pizza', 0]], 'temperature': [['fridge', 0], ['pizza', 1]], 'solid': [['fridge', 0], ['pizza', 0]], 'contain': [['fridge', 8], ['pizza', 0]], 'running': [['fridge', 2], ['pizza', 0]], 'moveable': [['fridge', 2], ['pizza', 2]], 'mixed': [['fridge', 0], ['pizza', 0]], 'edible': [['fridge', 0], ['pizza', 0]]}\n",
            "      {'h_location': [['John', 0]], 'conscious': [['John', 2]], 'wearing': [['John', 0]], 'h_wet': [['John', 0]], 'hygiene': [['John', 0]], 'location': [['knife', 2], ['slices', 2], ['hot pizza', 0]], 'exist': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'clean': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'power': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'functional': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'pieces': [['knife', 0], ['slices', 0], ['hot pizza', 4]], 'wet': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'open': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'temperature': [['knife', 0], ['slices', 0], ['hot pizza', 2]], 'solid': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'contain': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'running': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'moveable': [['knife', 2], ['slices', 2], ['hot pizza', 2]], 'mixed': [['knife', 0], ['slices', 0], ['hot pizza', 0]], 'edible': [['knife', 0], ['slices', 0], ['hot pizza', 0]]}\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n",
            "{\n",
            "  story_id: \n",
            "    33,\n",
            "  worker_id: \n",
            "    A1F01FVEPYCPHO,\n",
            "  type: \n",
            "    None,\n",
            "  idx: \n",
            "    None,\n",
            "  aug: \n",
            "    False,\n",
            "  actor: \n",
            "    Mary,\n",
            "  location: \n",
            "    bathroom,\n",
            "  objects: \n",
            "    washing machine, cabinet, toothpaste, bleach, socks, mirror,\n",
            "  sentences: \n",
            "    [\n",
            "      Mary took off her socks.\n",
            "      Mary put the socks in the washing machine.\n",
            "      Mary opened the cabinet.\n",
            "      Mary took out the toothbrush and toothpaste.\n",
            "      Mary brushed her teeth while looking in the mirror.\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  example_id: \n",
            "    33,\n",
            "  plausible: \n",
            "    True,\n",
            "  breakpoint: \n",
            "    -1,\n",
            "  confl_sents: \n",
            "    [],\n",
            "  confl_pairs: \n",
            "    [],\n",
            "  states: \n",
            "    [\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 8]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 0]], 'location': [['socks', 5]], 'exist': [['socks', 2]], 'clean': [['socks', 0]], 'power': [['socks', 0]], 'functional': [['socks', 2]], 'pieces': [['socks', 0]], 'wet': [['socks', 0]], 'open': [['socks', 0]], 'temperature': [['socks', 0]], 'solid': [['socks', 0]], 'contain': [['socks', 0]], 'running': [['socks', 0]], 'moveable': [['socks', 2]], 'mixed': [['socks', 0]], 'edible': [['socks', 0]]}\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 0]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 0]], 'location': [['socks', 6], ['washing machine', 0]], 'exist': [['socks', 2], ['washing machine', 2]], 'clean': [['socks', 0], ['washing machine', 0]], 'power': [['socks', 0], ['washing machine', 0]], 'functional': [['socks', 2], ['washing machine', 2]], 'pieces': [['socks', 0], ['washing machine', 0]], 'wet': [['socks', 0], ['washing machine', 0]], 'open': [['socks', 0], ['washing machine', 8]], 'temperature': [['socks', 0], ['washing machine', 0]], 'solid': [['socks', 0], ['washing machine', 0]], 'contain': [['socks', 0], ['washing machine', 6]], 'running': [['socks', 0], ['washing machine', 0]], 'moveable': [['socks', 2], ['washing machine', 2]], 'mixed': [['socks', 0], ['washing machine', 0]], 'edible': [['socks', 0], ['washing machine', 0]]}\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 0]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 0]], 'location': [['cabinet', 0]], 'exist': [['cabinet', 2]], 'clean': [['cabinet', 0]], 'power': [['cabinet', 0]], 'functional': [['cabinet', 2]], 'pieces': [['cabinet', 0]], 'wet': [['cabinet', 0]], 'open': [['cabinet', 4]], 'temperature': [['cabinet', 0]], 'solid': [['cabinet', 0]], 'contain': [['cabinet', 0]], 'running': [['cabinet', 0]], 'moveable': [['cabinet', 2]], 'mixed': [['cabinet', 0]], 'edible': [['cabinet', 0]]}\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 0]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 0]], 'location': [['toothbrush', 7], ['toothpaste', 7]], 'exist': [['toothbrush', 2], ['toothpaste', 2]], 'clean': [['toothbrush', 0], ['toothpaste', 0]], 'power': [['toothbrush', 0], ['toothpaste', 0]], 'functional': [['toothbrush', 2], ['toothpaste', 2]], 'pieces': [['toothbrush', 0], ['toothpaste', 0]], 'wet': [['toothbrush', 0], ['toothpaste', 0]], 'open': [['toothbrush', 0], ['toothpaste', 0]], 'temperature': [['toothbrush', 0], ['toothpaste', 0]], 'solid': [['toothbrush', 0], ['toothpaste', 0]], 'contain': [['toothbrush', 0], ['toothpaste', 0]], 'running': [['toothbrush', 0], ['toothpaste', 0]], 'moveable': [['toothbrush', 2], ['toothpaste', 2]], 'mixed': [['toothbrush', 0], ['toothpaste', 0]], 'edible': [['toothbrush', 0], ['toothpaste', 0]]}\n",
            "      {'h_location': [['Mary', 0]], 'conscious': [['Mary', 2]], 'wearing': [['Mary', 0]], 'h_wet': [['Mary', 0]], 'hygiene': [['Mary', 6]], 'location': [['mirror', 0], ['teeth', 0]], 'exist': [['mirror', 2], ['teeth', 2]], 'clean': [['mirror', 0], ['teeth', 6]], 'power': [['mirror', 0], ['teeth', 0]], 'functional': [['mirror', 2], ['teeth', 2]], 'pieces': [['mirror', 0], ['teeth', 0]], 'wet': [['mirror', 0], ['teeth', 0]], 'open': [['mirror', 0], ['teeth', 0]], 'temperature': [['mirror', 0], ['teeth', 0]], 'solid': [['mirror', 0], ['teeth', 0]], 'contain': [['mirror', 0], ['teeth', 0]], 'running': [['mirror', 0], ['teeth', 0]], 'moveable': [['mirror', 2], ['teeth', 0]], 'mixed': [['mirror', 0], ['teeth', 0]], 'edible': [['mirror', 0], ['teeth', 0]]}\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from www.utils import print_dict\n",
        "\n",
        "partitions = ['train', 'dev', 'test']\n",
        "subtasks = ['cloze', 'order']\n",
        "\n",
        "# We can split the data into multiple json files later\n",
        "data_file = os.path.join(DRIVE_PATH, 'all_data/www.json')\n",
        "with open(data_file, 'r') as f:\n",
        "  dataset = json.load(f)\n",
        "\n",
        "print('Preprocessed examples:')\n",
        "for ex_idx in [0,1,5,10]:\n",
        "  ex = dataset['dev'][list(dataset['dev'].keys())[ex_idx]]\n",
        "  print_dict(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_0WsycpFMdb"
      },
      "source": [
        "### Data Filtering and Sampling\n",
        "Since there is a big imbalance between plausible/implausible class labels, we will upsample the plausible stories.\n",
        "\n",
        "For now, we will also break the dataset into two sub-datasets: cloze and ordering.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-twYzY5rF1Mi"
      },
      "outputs": [],
      "source": [
        "cloze_dataset = {p: [] for p in dataset}\n",
        "order_dataset = {p: [] for p in dataset}\n",
        "\n",
        "for p in dataset:\n",
        "  for exid in dataset[p]:\n",
        "    ex = dataset[p][exid]\n",
        "\n",
        "    if ex['type'] == None:\n",
        "      continue\n",
        "    \n",
        "    ex_plaus = dataset[p][str(ex['story_id'])]\n",
        "\n",
        "    if ex['type'] == 'cloze':\n",
        "      cloze_dataset[p].append(ex)\n",
        "      cloze_dataset[p].append(ex_plaus) # For every implausible story, add a copy of its corresponding plausible story\n",
        "\n",
        "    # Exclude augmented ordering examples from dev and test, since the breakpoints aren't always accurate in those\n",
        "    elif ex['type'] == 'order' and not (p != 'train' and ex['aug']): \n",
        "      order_dataset[p].append(ex)\n",
        "      order_dataset[p].append(ex_plaus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz5tcmScJrka"
      },
      "source": [
        "\n",
        "\n",
        "### Convert TRIP to Two-Story Classification Task\n",
        "\n",
        "Ready the TRIP dataset for two-story classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af976ygKJv7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b73c577-a552-4e9a-d86e-7376239e596c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloze label distribution (train):\n",
            "[(1, 400), (0, 399)]\n",
            "Cloze label distribution (dev):\n",
            "[(0, 161), (1, 161)]\n",
            "Cloze label distribution (test):\n",
            "[(1, 176), (0, 175)]\n",
            "{\n",
            "  example_id: \n",
            "    0-C0,\n",
            "  stories: \n",
            "    [\n",
            "      {'story_id': 0, 'worker_id': 'A1F01FVEPYCPHO', 'type': 'cloze', 'idx': 0, 'aug': False, 'actor': 'Tom', 'location': 'kitchen', 'objects': 'dustbin, microwave, pan, plate, cereal, soup', 'sentences': ['Tom bought a new dustbin for the kitchen.', 'Tom threw a broken plate in the dustbin.', 'Tom got some soup from the fridge.', 'Tom put the soup in the microwave.', 'Tom ate the cold soup.'], 'length': 5, 'example_id': '0-C0', 'plausible': False, 'breakpoint': 4, 'confl_sents': [3], 'confl_pairs': [[3, 4]], 'states': [{'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['dustbin', 6]], 'exist': [['dustbin', 4]], 'clean': [['dustbin', 0]], 'power': [['dustbin', 0]], 'functional': [['dustbin', 2]], 'pieces': [['dustbin', 0]], 'wet': [['dustbin', 0]], 'open': [['dustbin', 0]], 'temperature': [['dustbin', 0]], 'solid': [['dustbin', 0]], 'contain': [['dustbin', 0]], 'running': [['dustbin', 0]], 'moveable': [['dustbin', 2]], 'mixed': [['dustbin', 0]], 'edible': [['dustbin', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['dustbin', 0], ['plate', 6]], 'exist': [['dustbin', 2], ['plate', 2]], 'clean': [['dustbin', 0], ['plate', 5]], 'power': [['dustbin', 0], ['plate', 0]], 'functional': [['dustbin', 2], ['plate', 1]], 'pieces': [['dustbin', 0], ['plate', 0]], 'wet': [['dustbin', 0], ['plate', 0]], 'open': [['dustbin', 0], ['plate', 0]], 'temperature': [['dustbin', 0], ['plate', 0]], 'solid': [['dustbin', 0], ['plate', 0]], 'contain': [['dustbin', 6], ['plate', 0]], 'running': [['dustbin', 0], ['plate', 0]], 'moveable': [['dustbin', 0], ['plate', 2]], 'mixed': [['dustbin', 0], ['plate', 0]], 'edible': [['dustbin', 0], ['plate', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['fridge', 0], ['soup', 2]], 'exist': [['fridge', 2], ['soup', 2]], 'clean': [['fridge', 0], ['soup', 0]], 'power': [['fridge', 0], ['soup', 0]], 'functional': [['fridge', 2], ['soup', 2]], 'pieces': [['fridge', 0], ['soup', 0]], 'wet': [['fridge', 0], ['soup', 0]], 'open': [['fridge', 8], ['soup', 0]], 'temperature': [['fridge', 0], ['soup', 1]], 'solid': [['fridge', 0], ['soup', 0]], 'contain': [['fridge', 8], ['soup', 0]], 'running': [['fridge', 0], ['soup', 0]], 'moveable': [['fridge', 2], ['soup', 2]], 'mixed': [['fridge', 0], ['soup', 0]], 'edible': [['fridge', 0], ['soup', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['microwave', 0], ['soup', 3]], 'exist': [['microwave', 2], ['soup', 2]], 'clean': [['microwave', 0], ['soup', 0]], 'power': [['microwave', 2], ['soup', 0]], 'functional': [['microwave', 2], ['soup', 2]], 'pieces': [['microwave', 0], ['soup', 0]], 'wet': [['microwave', 0], ['soup', 0]], 'open': [['microwave', 8], ['soup', 0]], 'temperature': [['microwave', 0], ['soup', 0]], 'solid': [['microwave', 0], ['soup', 0]], 'contain': [['microwave', 6], ['soup', 0]], 'running': [['microwave', 0], ['soup', 0]], 'moveable': [['microwave', 2], ['soup', 2]], 'mixed': [['microwave', 0], ['soup', 0]], 'edible': [['microwave', 0], ['soup', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['soup', 1]], 'exist': [['soup', 3]], 'clean': [['soup', 0]], 'power': [['soup', 0]], 'functional': [['soup', 2]], 'pieces': [['soup', 0]], 'wet': [['soup', 0]], 'open': [['soup', 0]], 'temperature': [['soup', 7]], 'solid': [['soup', 0]], 'contain': [['soup', 0]], 'running': [['soup', 0]], 'moveable': [['soup', 2]], 'mixed': [['soup', 0]], 'edible': [['soup', 0]]}]}\n",
            "      {'story_id': 0, 'worker_id': 'A1F01FVEPYCPHO', 'type': None, 'idx': None, 'aug': False, 'actor': 'Tom', 'location': 'kitchen', 'objects': 'dustbin, microwave, pan, plate, cereal, soup', 'sentences': ['Tom bought a new dustbin for the kitchen.', 'Tom threw a broken plate in the dustbin.', 'Tom got some soup from the fridge.', 'Tom put the soup in the microwave.', 'Tom turned on the microwave.'], 'length': 5, 'example_id': '0', 'plausible': True, 'breakpoint': -1, 'confl_sents': [], 'confl_pairs': [], 'states': [{'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['dustbin', 6]], 'exist': [['dustbin', 4]], 'clean': [['dustbin', 0]], 'power': [['dustbin', 0]], 'functional': [['dustbin', 2]], 'pieces': [['dustbin', 0]], 'wet': [['dustbin', 0]], 'open': [['dustbin', 0]], 'temperature': [['dustbin', 0]], 'solid': [['dustbin', 0]], 'contain': [['dustbin', 0]], 'running': [['dustbin', 0]], 'moveable': [['dustbin', 2]], 'mixed': [['dustbin', 0]], 'edible': [['dustbin', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['dustbin', 0], ['plate', 6]], 'exist': [['dustbin', 2], ['plate', 2]], 'clean': [['dustbin', 0], ['plate', 5]], 'power': [['dustbin', 0], ['plate', 0]], 'functional': [['dustbin', 2], ['plate', 1]], 'pieces': [['dustbin', 0], ['plate', 0]], 'wet': [['dustbin', 0], ['plate', 0]], 'open': [['dustbin', 0], ['plate', 0]], 'temperature': [['dustbin', 0], ['plate', 0]], 'solid': [['dustbin', 0], ['plate', 0]], 'contain': [['dustbin', 6], ['plate', 0]], 'running': [['dustbin', 0], ['plate', 0]], 'moveable': [['dustbin', 0], ['plate', 2]], 'mixed': [['dustbin', 0], ['plate', 0]], 'edible': [['dustbin', 0], ['plate', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['fridge', 0], ['soup', 2]], 'exist': [['fridge', 2], ['soup', 2]], 'clean': [['fridge', 0], ['soup', 0]], 'power': [['fridge', 0], ['soup', 0]], 'functional': [['fridge', 2], ['soup', 2]], 'pieces': [['fridge', 0], ['soup', 0]], 'wet': [['fridge', 0], ['soup', 0]], 'open': [['fridge', 8], ['soup', 0]], 'temperature': [['fridge', 0], ['soup', 1]], 'solid': [['fridge', 0], ['soup', 0]], 'contain': [['fridge', 8], ['soup', 0]], 'running': [['fridge', 0], ['soup', 0]], 'moveable': [['fridge', 2], ['soup', 2]], 'mixed': [['fridge', 0], ['soup', 0]], 'edible': [['fridge', 0], ['soup', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['microwave', 0], ['soup', 3]], 'exist': [['microwave', 2], ['soup', 2]], 'clean': [['microwave', 0], ['soup', 0]], 'power': [['microwave', 2], ['soup', 0]], 'functional': [['microwave', 2], ['soup', 2]], 'pieces': [['microwave', 0], ['soup', 0]], 'wet': [['microwave', 0], ['soup', 0]], 'open': [['microwave', 8], ['soup', 0]], 'temperature': [['microwave', 0], ['soup', 0]], 'solid': [['microwave', 0], ['soup', 0]], 'contain': [['microwave', 6], ['soup', 0]], 'running': [['microwave', 0], ['soup', 0]], 'moveable': [['microwave', 2], ['soup', 2]], 'mixed': [['microwave', 0], ['soup', 0]], 'edible': [['microwave', 0], ['soup', 0]]}, {'h_location': [['Tom', 0]], 'conscious': [['Tom', 2]], 'wearing': [['Tom', 0]], 'h_wet': [['Tom', 0]], 'hygiene': [['Tom', 0]], 'location': [['microwave', 0]], 'exist': [['microwave', 2]], 'clean': [['microwave', 0]], 'power': [['microwave', 2]], 'functional': [['microwave', 2]], 'pieces': [['microwave', 0]], 'wet': [['microwave', 0]], 'open': [['microwave', 1]], 'temperature': [['microwave', 0]], 'solid': [['microwave', 0]], 'contain': [['microwave', 2]], 'running': [['microwave', 4]], 'moveable': [['microwave', 2]], 'mixed': [['microwave', 0]], 'edible': [['microwave', 0]]}]}\n",
            "    ],\n",
            "  length: \n",
            "    5,\n",
            "  label: \n",
            "    1,\n",
            "  breakpoint: \n",
            "    4,\n",
            "  confl_sents: \n",
            "    [\n",
            "      3\n",
            "    ],\n",
            "  confl_pairs: \n",
            "    [\n",
            "      [3, 4]\n",
            "    ],\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from www.utils import print_dict\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "data_file = os.path.join(DRIVE_PATH, 'all_data/www_2s_new.json')\n",
        "with open(data_file, 'r') as f:\n",
        "  cloze_dataset_2s, order_dataset_2s = json.load(f)  \n",
        "\n",
        "for p in cloze_dataset_2s:\n",
        "  label_dist = Counter([ex['label'] for ex in cloze_dataset_2s[p]])\n",
        "  print('Cloze label distribution (%s):' % p)\n",
        "  print(label_dist.most_common())\n",
        "print_dict(cloze_dataset_2s['train'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxIYaEobhR7J"
      },
      "source": [
        "---\n",
        "\n",
        "# TRIP Results\n",
        "\n",
        "Contains code for the tiered and random TRIP baselines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbUgyE0bbJqn"
      },
      "outputs": [],
      "source": [
        "if task_name != 'trip':\n",
        "  raise ValueError('Please configure task_name in first cell to \"trip\" to run TRIP results!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7VlN2jUwvcC"
      },
      "source": [
        "## Random Tiered Classifier for TRIP\n",
        "\n",
        "For the random baseline, we average the results of 10 runs. Running the below will report (mean, variance) for each evaluation partition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYE2UIiASDv",
        "outputId": "4636bb2f-bed9-4a5c-ac33-5287b46bba4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n",
            "[========================================================================] 100%\n",
            "[========================================================================] 100%\n"
          ]
        }
      ],
      "source": [
        "from www.dataset.prepro import get_tiered_data\n",
        "from www.dataset.featurize import add_bert_features_tiered, get_tensor_dataset_tiered\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from www.dataset.ann import att_to_num_classes, idx_to_att\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from www.utils import print_dict\n",
        "\n",
        "tiered_dataset = cloze_dataset_2s\n",
        "\n",
        "seq_length = 16 # Max sequence length to pad to\n",
        "\n",
        "tiered_dataset = get_tiered_data(tiered_dataset)\n",
        "tiered_dataset = add_bert_features_tiered(tiered_dataset, tokenizer, seq_length, add_segment_ids=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL20bloxwxci",
        "outputId": "f1de5d3b-1d05-4c4f-d3b2-6c941563eda6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting dev...\n",
            "starting run 0...\n",
            "starting run 1...\n",
            "starting run 2...\n",
            "starting run 3...\n",
            "starting run 4...\n",
            "starting run 5...\n",
            "starting run 6...\n",
            "starting run 7...\n",
            "starting run 8...\n",
            "starting run 9...\n",
            "RANDOM BASELINE (dev, 10 runs)\n",
            "{\n",
            "  story_accuracy: \n",
            "    (0.48526471458148474, 0.005838153452381435),\n",
            "  confl_f1: \n",
            "    (0.4858379357901971, 0.0009035340288377808),\n",
            "  precondition_f1: \n",
            "    (0.04021867966544108, 2.2368712110786947e-05),\n",
            "  effect_f1: \n",
            "    (0.04021808787991677, 0.00011561658250892263),\n",
            "  verifiability: \n",
            "    (0.0, 0.0),\n",
            "  consistency: \n",
            "    (0.11871265897663415, 0.0015433015309350296),\n",
            "}\n",
            "\n",
            "\n",
            "starting test...\n",
            "starting run 0...\n",
            "starting run 1...\n",
            "starting run 2...\n",
            "starting run 3...\n",
            "starting run 4...\n",
            "starting run 5...\n",
            "starting run 6...\n",
            "starting run 7...\n",
            "starting run 8...\n",
            "starting run 9...\n",
            "RANDOM BASELINE (test, 10 runs)\n",
            "{\n",
            "  story_accuracy: \n",
            "    (0.4955748136713214, 0.003192130759929981),\n",
            "  confl_f1: \n",
            "    (0.4851803944004406, 0.0002539928639247852),\n",
            "  precondition_f1: \n",
            "    (0.04007687439778471, 6.688983371310916e-05),\n",
            "  effect_f1: \n",
            "    (0.040287447175201524, 4.0452959606929534e-05),\n",
            "  verifiability: \n",
            "    (0.0, 0.0),\n",
            "  consistency: \n",
            "    (0.10577139404624236, 0.004314649273848388),\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from www.dataset.prepro import get_tiered_data, balance_labels\n",
        "from www.dataset.featurize import add_bert_features_tiered, get_tensor_dataset_tiered\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from www.dataset.ann import att_to_num_classes, idx_to_att, att_default_values\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from www.utils import print_dict\n",
        "import numpy as np\n",
        "\n",
        "# Have to add BERT input IDs and tensorize again\n",
        "num_runs = 10\n",
        "stories = []\n",
        "pred_stories = []\n",
        "conflicts = []\n",
        "pred_conflicts = []\n",
        "preconditions = []\n",
        "pred_preconditions = []\n",
        "effects = []\n",
        "pred_effects = []\n",
        "verifiability = []\n",
        "consistency = []\n",
        "for p in tiered_dataset:\n",
        "  if p == 'train':\n",
        "    continue\n",
        "  metr_avg = {}\n",
        "  print('starting %s...' % p)\n",
        "  for r in range(num_runs):\n",
        "    print('starting run %s...' % str(r))\n",
        "    for ex in tiered_dataset[p]:\n",
        "      verifiable = True\n",
        "      consistent = True\n",
        "\n",
        "      stories.append(ex['label'])\n",
        "      pred_stories.append(np.random.randint(2))\n",
        "\n",
        "      if stories[-1] != pred_stories[-1]:\n",
        "        verifiable = False\n",
        "\n",
        "      labels_ex_p = []\n",
        "      preds_ex_p = []\n",
        "\n",
        "      labels_ex_e = []\n",
        "      preds_ex_e = []\n",
        "\n",
        "      labels_ex_c = []\n",
        "      preds_ex_c = []\n",
        "\n",
        "      for si, story in enumerate(ex['stories']):\n",
        "        labels_story_p = []\n",
        "        preds_story_p = []\n",
        "\n",
        "        labels_story_e = []\n",
        "        preds_story_e = []      \n",
        "\n",
        "        for ent_ann in story['entities']:\n",
        "          entity = ent_ann['entity']\n",
        "\n",
        "          if si == 1 - ex['label']:\n",
        "            labels_ex_c.append(ent_ann['conflict_span_onehot'])\n",
        "            pred = np.zeros(ent_ann['conflict_span_onehot'].shape)\n",
        "            for cs in np.random.choice(len(pred), size=2, replace=False):\n",
        "              pred[cs] = 1\n",
        "            preds_ex_c.append(pred)\n",
        "\n",
        "          labels_ent = []\n",
        "          preds_ent = []\n",
        "          for s, sent_ann in enumerate(ent_ann['preconditions']):\n",
        "            if s < len(story['sentences']):\n",
        "              if entity in story['sentences'][s]:\n",
        "\n",
        "                labels_ent.append(sent_ann)\n",
        "                sent_ann_pred = []\n",
        "                for i, l in enumerate(sent_ann):\n",
        "                  pl = np.random.randint(att_to_num_classes[idx_to_att[i]])\n",
        "                  if pl > 0 and pl != att_default_values[idx_to_att[i]]:\n",
        "                    if pl != l:\n",
        "                      verifiable = False\n",
        "                  sent_ann_pred.append(pl)\n",
        "                preds_ent.append(sent_ann_pred)\n",
        "\n",
        "          labels_story_p.append(labels_ent)\n",
        "          preds_story_p.append(preds_ent)\n",
        "\n",
        "          labels_ent = []\n",
        "          preds_ent = []\n",
        "          for s, sent_ann in enumerate(ent_ann['effects']):\n",
        "            if s < len(story['sentences']):\n",
        "              if entity in story['sentences'][s]:\n",
        "    \n",
        "                labels_ent.append(sent_ann)\n",
        "                sent_ann_pred = []\n",
        "                for i, l in enumerate(sent_ann):\n",
        "                  pl = np.random.randint(att_to_num_classes[idx_to_att[i]])\n",
        "                  if pl > 0 and pl != att_default_values[idx_to_att[i]]:\n",
        "                    if pl != l:\n",
        "                      verifiable = False\n",
        "                  sent_ann_pred.append(pl)\n",
        "                preds_ent.append(sent_ann_pred)\n",
        "\n",
        "          labels_story_e.append(labels_ent)\n",
        "          preds_story_e.append(preds_ent)\n",
        "\n",
        "        labels_ex_p.append(labels_story_p)\n",
        "        preds_ex_p.append(preds_story_p)\n",
        "\n",
        "        labels_ex_e.append(labels_story_e)\n",
        "        preds_ex_e.append(preds_story_e)\n",
        "\n",
        "      conflicts.append(labels_ex_c)\n",
        "      pred_conflicts.append(preds_ex_c)\n",
        "\n",
        "      preconditions.append(labels_ex_p)\n",
        "      pred_preconditions.append(preds_ex_p)\n",
        "\n",
        "      effects.append(labels_ex_e)\n",
        "      pred_effects.append(preds_ex_e)\n",
        "\n",
        "      p_confl = np.nonzero(np.sum(np.array(preds_ex_c), axis=0))[0]\n",
        "      l_confl = np.nonzero(np.sum(np.array(labels_ex_c), axis=0))[0]\n",
        "      assert len(l_confl) == 2, str(labels_ex_c)\n",
        "      if not (p_confl[0] == l_confl[0] and p_confl[1] == l_confl[1]):\n",
        "        verifiable = False    \n",
        "        consistent = False\n",
        "\n",
        "      verifiability.append(1 if verifiable else 0)\n",
        "      consistency.append(1 if consistent else 0)\n",
        "\n",
        "    # Compute metrics\n",
        "    metr = {}\n",
        "    metr['story_accuracy'] = accuracy_score(stories, pred_stories)\n",
        "\n",
        "    conflicts_flat = [c for c_ex in conflicts for c_ent in c_ex for c in c_ent]\n",
        "    pred_conflicts_flat = [c for c_ex in pred_conflicts for c_ent in c_ex for c in c_ent]\n",
        "    metr['confl_f1'] = f1_score(conflicts_flat, pred_conflicts_flat, average='macro')\n",
        "\n",
        "    preconditions_flat = [p for p_ex in preconditions for p_story in p_ex for p_sent in p_story for p_ent in p_sent for p in p_ent]\n",
        "    pred_preconditions_flat = [p for p_ex in pred_preconditions for p_story in p_ex for p_sent in p_story for p_ent in p_sent for p in p_ent]\n",
        "    metr['precondition_f1'] = f1_score(preconditions_flat, pred_preconditions_flat, average='macro')\n",
        "\n",
        "    effects_flat = [p for p_ex in effects for p_story in p_ex for p_sent in p_story for p_ent in p_sent for p in p_ent]\n",
        "    pred_effects_flat = [p for p_ex in pred_effects for p_story in p_ex for p_sent in p_story for p_ent in p_sent for p in p_ent]\n",
        "    metr['effect_f1'] = f1_score(effects_flat, pred_effects_flat, average='macro')\n",
        "\n",
        "    metr['verifiability'] = np.mean(verifiability)\n",
        "    metr['consistency'] = np.mean(consistency)\n",
        "\n",
        "    for k in metr:\n",
        "      if k not in metr_avg:\n",
        "        metr_avg[k] = []\n",
        "      metr_avg[k].append(metr[k])\n",
        "\n",
        "  for k in metr_avg:\n",
        "    metr_avg[k] = (np.mean(metr_avg[k]), np.var(metr_avg[k]) ** 0.5)\n",
        "  print('RANDOM BASELINE (%s, %s runs)' % (str(p), str(num_runs)))\n",
        "  print_dict(metr_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ctQweSlAceo"
      },
      "source": [
        "## Transformer-Based Tiered Classifier for TRIP\n",
        "\n",
        "This is the baseline model presented in the paper. Based on the settings above, the below cells can be used for training and evaluating models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q-xjfYU_cV8"
      },
      "source": [
        "### Featurization for Tiered Classification\n",
        "\n",
        "Get the data ready for input to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLCJXeMb_cV9",
        "outputId": "574c3ed5-769a-4553-f305-08f4ce3e7129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[========================================================================] 100%\n",
            "[========================================================================] 100%\n",
            "[========================================================================] 100%\n"
          ]
        }
      ],
      "source": [
        "from www.dataset.prepro import get_tiered_data, balance_labels\n",
        "from www.dataset.featurize import add_bert_features_tiered, get_tensor_dataset_tiered\n",
        "from collections import Counter\n",
        "\n",
        "tiered_dataset = cloze_dataset_2s\n",
        "\n",
        "# Debug the code on a small amount of data\n",
        "debug = False\n",
        "if debug:\n",
        "  for k in tiered_dataset:\n",
        "    tiered_dataset[k] = tiered_dataset[k][:200]\n",
        "\n",
        "# train_spans = True\n",
        "train_spans = False\n",
        "if train_spans:\n",
        "  tiered_dataset = get_story_spans_2s(tiered_dataset, train_only=True)\n",
        "  tiered_dataset['train'] = [ex for ex in tiered_dataset['train'] if ex['label'] != -1] # For now, ignore examples where both stories are plausible :(\n",
        "\n",
        "seq_length = 16 # Max sequence length to pad to\n",
        "\n",
        "tiered_dataset = get_tiered_data(tiered_dataset)\n",
        "tiered_dataset = add_bert_features_tiered(tiered_dataset, tokenizer, seq_length, add_segment_ids=True)\n",
        "\n",
        "tiered_tensor_dataset = {}\n",
        "max_story_length = max([len(ex['stories'][0]['sentences']) for p in tiered_dataset for ex in tiered_dataset[p]])\n",
        "for p in tiered_dataset:\n",
        "  tiered_tensor_dataset[p] = get_tensor_dataset_tiered(tiered_dataset[p], max_story_length, add_segment_ids=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fQ6wXQIBdq1"
      },
      "source": [
        "### Train Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-BMInyrBdq2"
      },
      "source": [
        "#### Configure Hyperparameters\n",
        "We will perform grid search over (batch size, learning rate). Configure the training sub-task, search space and set the maximum number of training epochs here. Currently configured for re-training the best RoBERTa-based model instance. Read code comments for more information.\n",
        "\n",
        "**Additional configuration options:**\n",
        "* Change the `generate_learning_curve` variable to `True` to generate data for training curves in the style presented in the paper.\n",
        "* You may ablate the input to the Conflict Detector based on a few pre-defined ablation modes. To do so, change the `ablation` variable based on the comments in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvfTuEYRBdq3"
      },
      "outputs": [],
      "source": [
        "from www.dataset.ann import att_to_idx, att_to_num_classes, att_types\n",
        "\n",
        "subtask = 'cloze'\n",
        "batch_sizes = [config_batch_size]\n",
        "learning_rates = [config_lr]\n",
        "epochs = config_epochs\n",
        "eval_batch_size = 4\n",
        "generate_learning_curve = False # Generate data for training curve figure in TRIP paper\n",
        "\n",
        "num_state_labels = {}\n",
        "for att in att_to_idx:\n",
        "  if att_types[att] == 'default':\n",
        "    num_state_labels[att_to_idx[att]] = 3\n",
        "  else:\n",
        "    num_state_labels[att_to_idx[att]] = att_to_num_classes[att] # Location attributes fall into this since they don't have well-define pre- and post-condition yet\n",
        "\n",
        "# Ablation options:\n",
        "# - attributes: skip attribute prediction phase\n",
        "# - embeddings: DON'T input contextual embeddings to conflict detector\n",
        "# - states: DON'T input states to conflict detector\n",
        "# - states-labels: in states input to conflict detector, include predicted labels\n",
        "# - states-logits: in states input to conflict detector, include state logits (preferred)\n",
        "# - states-teacher-forcing: train conflict detector on ground truth state labels (not predictions)\n",
        "# - states-attention: re-weight input to conflict detector with weights conditioned on states representation\n",
        "ablation = ['attributes', 'states-logits'] # This is the default mode presented in the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fRC3cnLBdq3"
      },
      "source": [
        "#### Perform Grid Search\n",
        "\n",
        "Perform hyperparameter tuning to find the best story classification model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7d999932e6a049dc99989e043e81e57a",
            "ec038468df534ed9871bdb8674ba1318",
            "781444ccbdc343148ace0a165e3f20f5",
            "c7062e9e76d54f328c27c700ddb5e8bc",
            "0d097e0ec7ef413ab12bb5b721a4103c",
            "816fd3679da94aabb2b9d95a1356665e",
            "f7f29ecd7db34b4cb430cb68a5282783",
            "13b7b584a5144922a3708aa9da75c803",
            "8ec8bd329a6d4e40b3828bbda2407dc4",
            "a2c539694b94446697ee00944bed0f1a",
            "1576720784c34573a14d4c76a9778388"
          ]
        },
        "id": "DWnCen7NBdq3",
        "outputId": "baddc8d8-7fc5-4bcc-f696-a780b529ada7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning grid search for the cloze sub-task over 1 parameter combination(s)!\n",
            "\n",
            "TRAINING MODEL: bs=4, lr=1e-05\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d999932e6a049dc99989e043e81e57a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n",
            "[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:33s.\n",
            "[0] Validation results:\n",
            "[0] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9851019240648204,\n",
            "  f1: \n",
            "    0.11027722860336263,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9621024611217485,\n",
            "  f1_1: \n",
            "    0.32689507987321836,\n",
            "  accuracy_2: \n",
            "    0.9988791855414935,\n",
            "  f1_2: \n",
            "    0.33314642617946205,\n",
            "  accuracy_3: \n",
            "    0.9985989819268668,\n",
            "  f1_3: \n",
            "    0.3330996666355111,\n",
            "  accuracy_4: \n",
            "    0.9996964460841545,\n",
            "  f1_4: \n",
            "    0.3332827333341118,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9320739737542614,\n",
            "  f1_6: \n",
            "    0.32161431581322086,\n",
            "  accuracy_7: \n",
            "    0.9982370522579741,\n",
            "  f1_7: \n",
            "    0.3330392494824319,\n",
            "  accuracy_8: \n",
            "    0.9921075981880166,\n",
            "  f1_8: \n",
            "    0.33201272163224477,\n",
            "  accuracy_9: \n",
            "    0.9327277821883903,\n",
            "  f1_9: \n",
            "    0.32173104106510736,\n",
            "  accuracy_10: \n",
            "    0.9950614112922057,\n",
            "  f1_10: \n",
            "    0.33250819771263823,\n",
            "  accuracy_11: \n",
            "    0.997151263251296,\n",
            "  f1_11: \n",
            "    0.3328578666354885,\n",
            "  accuracy_12: \n",
            "    0.992352776350815,\n",
            "  f1_12: \n",
            "    0.33205390401740803,\n",
            "  accuracy_13: \n",
            "    0.9977817213842058,\n",
            "  f1_13: \n",
            "    0.3329632097120438,\n",
            "  accuracy_14: \n",
            "    0.9946761313220941,\n",
            "  f1_14: \n",
            "    0.3324436536180308,\n",
            "  accuracy_15: \n",
            "    0.9935319665623686,\n",
            "  f1_15: \n",
            "    0.33225183016105414,\n",
            "  accuracy_16: \n",
            "    0.9929131835800682,\n",
            "  f1_16: \n",
            "    0.332147997133322,\n",
            "  accuracy_17: \n",
            "    0.9553308737682716,\n",
            "  f1_17: \n",
            "    0.3257184028150961,\n",
            "  accuracy_18: \n",
            "    0.9994045673189185,\n",
            "  f1_18: \n",
            "    0.33323406499934793,\n",
            "  accuracy_19: \n",
            "    0.9974548171671415,\n",
            "  f1_19: \n",
            "    0.33290859567702796,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9847440806986411,\n",
            "  f1: \n",
            "    0.1102570452589541,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9621024611217485,\n",
            "  f1_1: \n",
            "    0.32689507987321836,\n",
            "  accuracy_2: \n",
            "    0.9982020268061458,\n",
            "  f1_2: \n",
            "    0.33303340149965915,\n",
            "  accuracy_3: \n",
            "    0.9982954280110213,\n",
            "  f1_3: \n",
            "    0.3330489956648243,\n",
            "  accuracy_4: \n",
            "    0.9990659879512446,\n",
            "  f1_4: \n",
            "    0.3331775919263655,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9322140755615748,\n",
            "  f1_6: \n",
            "    0.3216393350171402,\n",
            "  accuracy_7: \n",
            "    0.9966725820763088,\n",
            "  f1_7: \n",
            "    0.3327778394993149,\n",
            "  accuracy_8: \n",
            "    0.99203754728436,\n",
            "  f1_8: \n",
            "    0.332000953374516,\n",
            "  accuracy_9: \n",
            "    0.9326460561341241,\n",
            "  f1_9: \n",
            "    0.3217164547276004,\n",
            "  accuracy_10: \n",
            "    0.9949329846355018,\n",
            "  f1_10: \n",
            "    0.3324866857845145,\n",
            "  accuracy_11: \n",
            "    0.9962989772568066,\n",
            "  f1_11: \n",
            "    0.33271535262914725,\n",
            "  accuracy_12: \n",
            "    0.9960070984915705,\n",
            "  f1_12: \n",
            "    0.3326665184855894,\n",
            "  accuracy_13: \n",
            "    0.9961472002988838,\n",
            "  f1_13: \n",
            "    0.332689960656786,\n",
            "  accuracy_14: \n",
            "    0.9944776537617335,\n",
            "  f1_14: \n",
            "    0.332410393898063,\n",
            "  accuracy_15: \n",
            "    0.9883365245411666,\n",
            "  f1_15: \n",
            "    0.3313780178699001,\n",
            "  accuracy_16: \n",
            "    0.9929482090318965,\n",
            "  f1_16: \n",
            "    0.33215387619605546,\n",
            "  accuracy_17: \n",
            "    0.9553191986176621,\n",
            "  f1_17: \n",
            "    0.32571636702353157,\n",
            "  accuracy_18: \n",
            "    0.999182739457339,\n",
            "  f1_18: \n",
            "    0.4997956013408552,\n",
            "  accuracy_19: \n",
            "    0.9980385746976136,\n",
            "  f1_19: \n",
            "    0.33300610820244325,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9704151683556718,\n",
            "  f1: \n",
            "    0.49249274160099543,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.40993788819875776,\n",
            "  f1: \n",
            "    0.4098468186904348,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[0] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Finished epoch.\n",
            "[1] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n",
            "[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:33s.\n",
            "[1] Validation results:\n",
            "[1] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9851019240648204,\n",
            "  f1: \n",
            "    0.11027722860336263,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9621024611217485,\n",
            "  f1_1: \n",
            "    0.32689507987321836,\n",
            "  accuracy_2: \n",
            "    0.9988791855414935,\n",
            "  f1_2: \n",
            "    0.33314642617946205,\n",
            "  accuracy_3: \n",
            "    0.9985989819268668,\n",
            "  f1_3: \n",
            "    0.3330996666355111,\n",
            "  accuracy_4: \n",
            "    0.9996964460841545,\n",
            "  f1_4: \n",
            "    0.3332827333341118,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9320739737542614,\n",
            "  f1_6: \n",
            "    0.32161431581322086,\n",
            "  accuracy_7: \n",
            "    0.9982370522579741,\n",
            "  f1_7: \n",
            "    0.3330392494824319,\n",
            "  accuracy_8: \n",
            "    0.9921075981880166,\n",
            "  f1_8: \n",
            "    0.33201272163224477,\n",
            "  accuracy_9: \n",
            "    0.9327277821883903,\n",
            "  f1_9: \n",
            "    0.32173104106510736,\n",
            "  accuracy_10: \n",
            "    0.9950614112922057,\n",
            "  f1_10: \n",
            "    0.33250819771263823,\n",
            "  accuracy_11: \n",
            "    0.997151263251296,\n",
            "  f1_11: \n",
            "    0.3328578666354885,\n",
            "  accuracy_12: \n",
            "    0.992352776350815,\n",
            "  f1_12: \n",
            "    0.33205390401740803,\n",
            "  accuracy_13: \n",
            "    0.9977817213842058,\n",
            "  f1_13: \n",
            "    0.3329632097120438,\n",
            "  accuracy_14: \n",
            "    0.9946761313220941,\n",
            "  f1_14: \n",
            "    0.3324436536180308,\n",
            "  accuracy_15: \n",
            "    0.9935319665623686,\n",
            "  f1_15: \n",
            "    0.33225183016105414,\n",
            "  accuracy_16: \n",
            "    0.9929131835800682,\n",
            "  f1_16: \n",
            "    0.332147997133322,\n",
            "  accuracy_17: \n",
            "    0.9553308737682716,\n",
            "  f1_17: \n",
            "    0.3257184028150961,\n",
            "  accuracy_18: \n",
            "    0.9994045673189185,\n",
            "  f1_18: \n",
            "    0.33323406499934793,\n",
            "  accuracy_19: \n",
            "    0.9974548171671415,\n",
            "  f1_19: \n",
            "    0.33290859567702796,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9847440806986411,\n",
            "  f1: \n",
            "    0.1102570452589541,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9621024611217485,\n",
            "  f1_1: \n",
            "    0.32689507987321836,\n",
            "  accuracy_2: \n",
            "    0.9982020268061458,\n",
            "  f1_2: \n",
            "    0.33303340149965915,\n",
            "  accuracy_3: \n",
            "    0.9982954280110213,\n",
            "  f1_3: \n",
            "    0.3330489956648243,\n",
            "  accuracy_4: \n",
            "    0.9990659879512446,\n",
            "  f1_4: \n",
            "    0.3331775919263655,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9322140755615748,\n",
            "  f1_6: \n",
            "    0.3216393350171402,\n",
            "  accuracy_7: \n",
            "    0.9966725820763088,\n",
            "  f1_7: \n",
            "    0.3327778394993149,\n",
            "  accuracy_8: \n",
            "    0.99203754728436,\n",
            "  f1_8: \n",
            "    0.332000953374516,\n",
            "  accuracy_9: \n",
            "    0.9326460561341241,\n",
            "  f1_9: \n",
            "    0.3217164547276004,\n",
            "  accuracy_10: \n",
            "    0.9949329846355018,\n",
            "  f1_10: \n",
            "    0.3324866857845145,\n",
            "  accuracy_11: \n",
            "    0.9962989772568066,\n",
            "  f1_11: \n",
            "    0.33271535262914725,\n",
            "  accuracy_12: \n",
            "    0.9960070984915705,\n",
            "  f1_12: \n",
            "    0.3326665184855894,\n",
            "  accuracy_13: \n",
            "    0.9961472002988838,\n",
            "  f1_13: \n",
            "    0.332689960656786,\n",
            "  accuracy_14: \n",
            "    0.9944776537617335,\n",
            "  f1_14: \n",
            "    0.332410393898063,\n",
            "  accuracy_15: \n",
            "    0.9883365245411666,\n",
            "  f1_15: \n",
            "    0.3313780178699001,\n",
            "  accuracy_16: \n",
            "    0.9929482090318965,\n",
            "  f1_16: \n",
            "    0.33215387619605546,\n",
            "  accuracy_17: \n",
            "    0.9553191986176621,\n",
            "  f1_17: \n",
            "    0.32571636702353157,\n",
            "  accuracy_18: \n",
            "    0.999182739457339,\n",
            "  f1_18: \n",
            "    0.4997956013408552,\n",
            "  accuracy_19: \n",
            "    0.9980385746976136,\n",
            "  f1_19: \n",
            "    0.33300610820244325,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9704151683556718,\n",
            "  f1: \n",
            "    0.49249274160099543,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.43788819875776397,\n",
            "  f1: \n",
            "    0.437839401977333,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Finished epoch.\n",
            "[2] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n",
            "[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:33s.\n",
            "[2] Validation results:\n",
            "[2] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9907982300471676,\n",
            "  f1: \n",
            "    0.18739643475410833,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9621024611217485,\n",
            "  f1_1: \n",
            "    0.32689507987321836,\n",
            "  accuracy_2: \n",
            "    0.9988791855414935,\n",
            "  f1_2: \n",
            "    0.33314642617946205,\n",
            "  accuracy_3: \n",
            "    0.9985989819268668,\n",
            "  f1_3: \n",
            "    0.3330996666355111,\n",
            "  accuracy_4: \n",
            "    0.9996964460841545,\n",
            "  f1_4: \n",
            "    0.3332827333341118,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9830126558632606,\n",
            "  f1_6: \n",
            "    0.6238844533556146,\n",
            "  accuracy_7: \n",
            "    0.9982370522579741,\n",
            "  f1_7: \n",
            "    0.3330392494824319,\n",
            "  accuracy_8: \n",
            "    0.9921075981880166,\n",
            "  f1_8: \n",
            "    0.33201272163224477,\n",
            "  accuracy_9: \n",
            "    0.984577126044926,\n",
            "  f1_9: \n",
            "    0.6275593443501686,\n",
            "  accuracy_10: \n",
            "    0.9950614112922057,\n",
            "  f1_10: \n",
            "    0.33250819771263823,\n",
            "  accuracy_11: \n",
            "    0.997151263251296,\n",
            "  f1_11: \n",
            "    0.3328578666354885,\n",
            "  accuracy_12: \n",
            "    0.992352776350815,\n",
            "  f1_12: \n",
            "    0.33205390401740803,\n",
            "  accuracy_13: \n",
            "    0.9977817213842058,\n",
            "  f1_13: \n",
            "    0.3329632097120438,\n",
            "  accuracy_14: \n",
            "    0.9946761313220941,\n",
            "  f1_14: \n",
            "    0.3324436536180308,\n",
            "  accuracy_15: \n",
            "    0.9935319665623686,\n",
            "  f1_15: \n",
            "    0.33225183016105414,\n",
            "  accuracy_16: \n",
            "    0.9929131835800682,\n",
            "  f1_16: \n",
            "    0.332147997133322,\n",
            "  accuracy_17: \n",
            "    0.9664689674496801,\n",
            "  f1_17: \n",
            "    0.5652653286406967,\n",
            "  accuracy_18: \n",
            "    0.9994045673189185,\n",
            "  f1_18: \n",
            "    0.33323406499934793,\n",
            "  accuracy_19: \n",
            "    0.9974548171671415,\n",
            "  f1_19: \n",
            "    0.33290859567702796,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9903224676598328,\n",
            "  f1: \n",
            "    0.18463987529324669,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9621024611217485,\n",
            "  f1_1: \n",
            "    0.32689507987321836,\n",
            "  accuracy_2: \n",
            "    0.9982020268061458,\n",
            "  f1_2: \n",
            "    0.33303340149965915,\n",
            "  accuracy_3: \n",
            "    0.9982954280110213,\n",
            "  f1_3: \n",
            "    0.3330489956648243,\n",
            "  accuracy_4: \n",
            "    0.9990659879512446,\n",
            "  f1_4: \n",
            "    0.3331775919263655,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9824989492364451,\n",
            "  f1_6: \n",
            "    0.6224318412164721,\n",
            "  accuracy_7: \n",
            "    0.9966725820763088,\n",
            "  f1_7: \n",
            "    0.3327778394993149,\n",
            "  accuracy_8: \n",
            "    0.99203754728436,\n",
            "  f1_8: \n",
            "    0.332000953374516,\n",
            "  accuracy_9: \n",
            "    0.982230420772428,\n",
            "  f1_9: \n",
            "    0.6213136469606582,\n",
            "  accuracy_10: \n",
            "    0.9949329846355018,\n",
            "  f1_10: \n",
            "    0.3324866857845145,\n",
            "  accuracy_11: \n",
            "    0.9962989772568066,\n",
            "  f1_11: \n",
            "    0.33271535262914725,\n",
            "  accuracy_12: \n",
            "    0.9960070984915705,\n",
            "  f1_12: \n",
            "    0.3326665184855894,\n",
            "  accuracy_13: \n",
            "    0.9961472002988838,\n",
            "  f1_13: \n",
            "    0.332689960656786,\n",
            "  accuracy_14: \n",
            "    0.9944776537617335,\n",
            "  f1_14: \n",
            "    0.332410393898063,\n",
            "  accuracy_15: \n",
            "    0.9883365245411666,\n",
            "  f1_15: \n",
            "    0.3313780178699001,\n",
            "  accuracy_16: \n",
            "    0.9929482090318965,\n",
            "  f1_16: \n",
            "    0.33215387619605546,\n",
            "  accuracy_17: \n",
            "    0.967017699528324,\n",
            "  f1_17: \n",
            "    0.5655197507227744,\n",
            "  accuracy_18: \n",
            "    0.999182739457339,\n",
            "  f1_18: \n",
            "    0.4997956013408552,\n",
            "  accuracy_19: \n",
            "    0.9980385746976136,\n",
            "  f1_19: \n",
            "    0.33300610820244325,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9704151683556718,\n",
            "  f1: \n",
            "    0.49249274160099543,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4503105590062112,\n",
            "  f1: \n",
            "    0.4502628406076682,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2] Finished epoch.\n",
            "[3] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n",
            "[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:33s.\n",
            "[3] Validation results:\n",
            "[3] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9909161490683229,\n",
            "  f1: \n",
            "    0.18782748823698092,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9621024611217485,\n",
            "  f1_1: \n",
            "    0.32689507987321836,\n",
            "  accuracy_2: \n",
            "    0.9988791855414935,\n",
            "  f1_2: \n",
            "    0.33314642617946205,\n",
            "  accuracy_3: \n",
            "    0.9985989819268668,\n",
            "  f1_3: \n",
            "    0.3330996666355111,\n",
            "  accuracy_4: \n",
            "    0.9996964460841545,\n",
            "  f1_4: \n",
            "    0.3332827333341118,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.983759865502265,\n",
            "  f1_6: \n",
            "    0.6256459045966619,\n",
            "  accuracy_7: \n",
            "    0.9982370522579741,\n",
            "  f1_7: \n",
            "    0.3330392494824319,\n",
            "  accuracy_8: \n",
            "    0.9921075981880166,\n",
            "  f1_8: \n",
            "    0.33201272163224477,\n",
            "  accuracy_9: \n",
            "    0.9853009853827115,\n",
            "  f1_9: \n",
            "    0.6292828392047288,\n",
            "  accuracy_10: \n",
            "    0.9950614112922057,\n",
            "  f1_10: \n",
            "    0.33250819771263823,\n",
            "  accuracy_11: \n",
            "    0.997151263251296,\n",
            "  f1_11: \n",
            "    0.3328578666354885,\n",
            "  accuracy_12: \n",
            "    0.992352776350815,\n",
            "  f1_12: \n",
            "    0.33205390401740803,\n",
            "  accuracy_13: \n",
            "    0.9977817213842058,\n",
            "  f1_13: \n",
            "    0.3329632097120438,\n",
            "  accuracy_14: \n",
            "    0.9946761313220941,\n",
            "  f1_14: \n",
            "    0.3324436536180308,\n",
            "  accuracy_15: \n",
            "    0.9935319665623686,\n",
            "  f1_15: \n",
            "    0.33225183016105414,\n",
            "  accuracy_16: \n",
            "    0.9929131835800682,\n",
            "  f1_16: \n",
            "    0.332147997133322,\n",
            "  accuracy_17: \n",
            "    0.9673562788959977,\n",
            "  f1_17: \n",
            "    0.5674303011244448,\n",
            "  accuracy_18: \n",
            "    0.9994045673189185,\n",
            "  f1_18: \n",
            "    0.33323406499934793,\n",
            "  accuracy_19: \n",
            "    0.9974548171671415,\n",
            "  f1_19: \n",
            "    0.33290859567702796,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9904158688647083,\n",
            "  f1: \n",
            "    0.18498568171032798,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9621024611217485,\n",
            "  f1_1: \n",
            "    0.32689507987321836,\n",
            "  accuracy_2: \n",
            "    0.9982020268061458,\n",
            "  f1_2: \n",
            "    0.33303340149965915,\n",
            "  accuracy_3: \n",
            "    0.9982954280110213,\n",
            "  f1_3: \n",
            "    0.3330489956648243,\n",
            "  accuracy_4: \n",
            "    0.9990659879512446,\n",
            "  f1_4: \n",
            "    0.3331775919263655,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.983152757670574,\n",
            "  f1_6: \n",
            "    0.6239722580209731,\n",
            "  accuracy_7: \n",
            "    0.9966725820763088,\n",
            "  f1_7: \n",
            "    0.3327778394993149,\n",
            "  accuracy_8: \n",
            "    0.99203754728436,\n",
            "  f1_8: \n",
            "    0.332000953374516,\n",
            "  accuracy_9: \n",
            "    0.9830126558632606,\n",
            "  f1_9: \n",
            "    0.6231762710307533,\n",
            "  accuracy_10: \n",
            "    0.9949329846355018,\n",
            "  f1_10: \n",
            "    0.3324866857845145,\n",
            "  accuracy_11: \n",
            "    0.9962989772568066,\n",
            "  f1_11: \n",
            "    0.33271535262914725,\n",
            "  accuracy_12: \n",
            "    0.9960070984915705,\n",
            "  f1_12: \n",
            "    0.3326665184855894,\n",
            "  accuracy_13: \n",
            "    0.9961472002988838,\n",
            "  f1_13: \n",
            "    0.332689960656786,\n",
            "  accuracy_14: \n",
            "    0.9944776537617335,\n",
            "  f1_14: \n",
            "    0.332410393898063,\n",
            "  accuracy_15: \n",
            "    0.9883365245411666,\n",
            "  f1_15: \n",
            "    0.3313780178699001,\n",
            "  accuracy_16: \n",
            "    0.9929482090318965,\n",
            "  f1_16: \n",
            "    0.33215387619605546,\n",
            "  accuracy_17: \n",
            "    0.9674496801008733,\n",
            "  f1_17: \n",
            "    0.5667424569605756,\n",
            "  accuracy_18: \n",
            "    0.999182739457339,\n",
            "  f1_18: \n",
            "    0.4997956013408552,\n",
            "  accuracy_19: \n",
            "    0.9980385746976136,\n",
            "  f1_19: \n",
            "    0.33300610820244325,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9704151683556718,\n",
            "  f1: \n",
            "    0.49249274160099543,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.45962732919254656,\n",
            "  f1: \n",
            "    0.45954392869545085,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3] Finished epoch.\n",
            "[4] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n",
            "[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:33s.\n",
            "[4] Validation results:\n",
            "[4] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.99271762480736,\n",
            "  f1: \n",
            "    0.19818395251261348,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9981786765049269,\n",
            "  f1_1: \n",
            "    0.6584992727659947,\n",
            "  accuracy_2: \n",
            "    0.9988791855414935,\n",
            "  f1_2: \n",
            "    0.33314642617946205,\n",
            "  accuracy_3: \n",
            "    0.9985989819268668,\n",
            "  f1_3: \n",
            "    0.3330996666355111,\n",
            "  accuracy_4: \n",
            "    0.9996964460841545,\n",
            "  f1_4: \n",
            "    0.3332827333341118,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9840634194181105,\n",
            "  f1_6: \n",
            "    0.6262325027268781,\n",
            "  accuracy_7: \n",
            "    0.9982370522579741,\n",
            "  f1_7: \n",
            "    0.3330392494824319,\n",
            "  accuracy_8: \n",
            "    0.9921075981880166,\n",
            "  f1_8: \n",
            "    0.33201272163224477,\n",
            "  accuracy_9: \n",
            "    0.9855344883949003,\n",
            "  f1_9: \n",
            "    0.629702992693177,\n",
            "  accuracy_10: \n",
            "    0.9950614112922057,\n",
            "  f1_10: \n",
            "    0.33250819771263823,\n",
            "  accuracy_11: \n",
            "    0.997151263251296,\n",
            "  f1_11: \n",
            "    0.3328578666354885,\n",
            "  accuracy_12: \n",
            "    0.992352776350815,\n",
            "  f1_12: \n",
            "    0.33205390401740803,\n",
            "  accuracy_13: \n",
            "    0.9977817213842058,\n",
            "  f1_13: \n",
            "    0.3329632097120438,\n",
            "  accuracy_14: \n",
            "    0.9946761313220941,\n",
            "  f1_14: \n",
            "    0.3324436536180308,\n",
            "  accuracy_15: \n",
            "    0.9935319665623686,\n",
            "  f1_15: \n",
            "    0.33225183016105414,\n",
            "  accuracy_16: \n",
            "    0.9929131835800682,\n",
            "  f1_16: \n",
            "    0.332147997133322,\n",
            "  accuracy_17: \n",
            "    0.9667725213655256,\n",
            "  f1_17: \n",
            "    0.5658062576757085,\n",
            "  accuracy_18: \n",
            "    0.9994045673189185,\n",
            "  f1_18: \n",
            "    0.33323406499934793,\n",
            "  accuracy_19: \n",
            "    0.9974548171671415,\n",
            "  f1_19: \n",
            "    0.33290859567702796,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9921805678793256,\n",
            "  f1: \n",
            "    0.19527365557472237,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9978517722878625,\n",
            "  f1_1: \n",
            "    0.6570671014835766,\n",
            "  accuracy_2: \n",
            "    0.9982020268061458,\n",
            "  f1_2: \n",
            "    0.33303340149965915,\n",
            "  accuracy_3: \n",
            "    0.9982954280110213,\n",
            "  f1_3: \n",
            "    0.3330489956648243,\n",
            "  accuracy_4: \n",
            "    0.9990659879512446,\n",
            "  f1_4: \n",
            "    0.3331775919263655,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9834096109839817,\n",
            "  f1_6: \n",
            "    0.6244175466469648,\n",
            "  accuracy_7: \n",
            "    0.9966725820763088,\n",
            "  f1_7: \n",
            "    0.3327778394993149,\n",
            "  accuracy_8: \n",
            "    0.99203754728436,\n",
            "  f1_8: \n",
            "    0.332000953374516,\n",
            "  accuracy_9: \n",
            "    0.9832461588754495,\n",
            "  f1_9: \n",
            "    0.6236003437233368,\n",
            "  accuracy_10: \n",
            "    0.9949329846355018,\n",
            "  f1_10: \n",
            "    0.3324866857845145,\n",
            "  accuracy_11: \n",
            "    0.9962989772568066,\n",
            "  f1_11: \n",
            "    0.33271535262914725,\n",
            "  accuracy_12: \n",
            "    0.9960070984915705,\n",
            "  f1_12: \n",
            "    0.3326665184855894,\n",
            "  accuracy_13: \n",
            "    0.9961472002988838,\n",
            "  f1_13: \n",
            "    0.332689960656786,\n",
            "  accuracy_14: \n",
            "    0.9944776537617335,\n",
            "  f1_14: \n",
            "    0.332410393898063,\n",
            "  accuracy_15: \n",
            "    0.9883365245411666,\n",
            "  f1_15: \n",
            "    0.3313780178699001,\n",
            "  accuracy_16: \n",
            "    0.9929482090318965,\n",
            "  f1_16: \n",
            "    0.33215387619605546,\n",
            "  accuracy_17: \n",
            "    0.9665039929015085,\n",
            "  f1_17: \n",
            "    0.5644089292852418,\n",
            "  accuracy_18: \n",
            "    0.999182739457339,\n",
            "  f1_18: \n",
            "    0.4997956013408552,\n",
            "  accuracy_19: \n",
            "    0.9980385746976136,\n",
            "  f1_19: \n",
            "    0.33300610820244325,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9678583103722038,\n",
            "  f1: \n",
            "    0.5113741499076827,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5652173913043478,\n",
            "  f1: \n",
            "    0.5651502874561098,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4] Finished epoch.\n",
            "[5] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n",
            "[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:33s.\n",
            "[5] Validation results:\n",
            "[5] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9921899079998132,\n",
            "  f1: \n",
            "    0.19624958215664146,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9978167468360342,\n",
            "  f1_1: \n",
            "    0.6569241573171326,\n",
            "  accuracy_2: \n",
            "    0.9988791855414935,\n",
            "  f1_2: \n",
            "    0.33314642617946205,\n",
            "  accuracy_3: \n",
            "    0.9985989819268668,\n",
            "  f1_3: \n",
            "    0.3330996666355111,\n",
            "  accuracy_4: \n",
            "    0.9996964460841545,\n",
            "  f1_4: \n",
            "    0.3332827333341118,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9792299070658012,\n",
            "  f1_6: \n",
            "    0.6150488250403358,\n",
            "  accuracy_7: \n",
            "    0.9982370522579741,\n",
            "  f1_7: \n",
            "    0.3330392494824319,\n",
            "  accuracy_8: \n",
            "    0.9921075981880166,\n",
            "  f1_8: \n",
            "    0.33201272163224477,\n",
            "  accuracy_9: \n",
            "    0.9814481856815953,\n",
            "  f1_9: \n",
            "    0.620151696166639,\n",
            "  accuracy_10: \n",
            "    0.9950614112922057,\n",
            "  f1_10: \n",
            "    0.33250819771263823,\n",
            "  accuracy_11: \n",
            "    0.997151263251296,\n",
            "  f1_11: \n",
            "    0.3328578666354885,\n",
            "  accuracy_12: \n",
            "    0.992352776350815,\n",
            "  f1_12: \n",
            "    0.33205390401740803,\n",
            "  accuracy_13: \n",
            "    0.9977817213842058,\n",
            "  f1_13: \n",
            "    0.3329632097120438,\n",
            "  accuracy_14: \n",
            "    0.9946761313220941,\n",
            "  f1_14: \n",
            "    0.3324436536180308,\n",
            "  accuracy_15: \n",
            "    0.9935319665623686,\n",
            "  f1_15: \n",
            "    0.33225183016105414,\n",
            "  accuracy_16: \n",
            "    0.9929131835800682,\n",
            "  f1_16: \n",
            "    0.332147997133322,\n",
            "  accuracy_17: \n",
            "    0.9654999299490964,\n",
            "  f1_17: \n",
            "    0.5620682320207094,\n",
            "  accuracy_18: \n",
            "    0.9994045673189185,\n",
            "  f1_18: \n",
            "    0.33323406499934793,\n",
            "  accuracy_19: \n",
            "    0.9974548171671415,\n",
            "  f1_19: \n",
            "    0.33290859567702796,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9918565824499136,\n",
            "  f1: \n",
            "    0.1939711232447833,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9979101480409097,\n",
            "  f1_1: \n",
            "    0.6573243914897088,\n",
            "  accuracy_2: \n",
            "    0.9982020268061458,\n",
            "  f1_2: \n",
            "    0.33303340149965915,\n",
            "  accuracy_3: \n",
            "    0.9982954280110213,\n",
            "  f1_3: \n",
            "    0.3330489956648243,\n",
            "  accuracy_4: \n",
            "    0.9990659879512446,\n",
            "  f1_4: \n",
            "    0.3331775919263655,\n",
            "  accuracy_5: \n",
            "    0.9784009713725307,\n",
            "  f1_5: \n",
            "    0.10989806476487228,\n",
            "  accuracy_6: \n",
            "    0.9799420912529772,\n",
            "  f1_6: \n",
            "    0.6160412810191102,\n",
            "  accuracy_7: \n",
            "    0.9966725820763088,\n",
            "  f1_7: \n",
            "    0.3327778394993149,\n",
            "  accuracy_8: \n",
            "    0.99203754728436,\n",
            "  f1_8: \n",
            "    0.332000953374516,\n",
            "  accuracy_9: \n",
            "    0.9792065567645822,\n",
            "  f1_9: \n",
            "    0.6141302697851825,\n",
            "  accuracy_10: \n",
            "    0.9949329846355018,\n",
            "  f1_10: \n",
            "    0.3324866857845145,\n",
            "  accuracy_11: \n",
            "    0.9962989772568066,\n",
            "  f1_11: \n",
            "    0.33271535262914725,\n",
            "  accuracy_12: \n",
            "    0.9960070984915705,\n",
            "  f1_12: \n",
            "    0.3326665184855894,\n",
            "  accuracy_13: \n",
            "    0.9961472002988838,\n",
            "  f1_13: \n",
            "    0.332689960656786,\n",
            "  accuracy_14: \n",
            "    0.9944776537617335,\n",
            "  f1_14: \n",
            "    0.332410393898063,\n",
            "  accuracy_15: \n",
            "    0.9883365245411666,\n",
            "  f1_15: \n",
            "    0.3313780178699001,\n",
            "  accuracy_16: \n",
            "    0.9929482090318965,\n",
            "  f1_16: \n",
            "    0.33215387619605546,\n",
            "  accuracy_17: \n",
            "    0.9674730304020922,\n",
            "  f1_17: \n",
            "    0.5646690935829871,\n",
            "  accuracy_18: \n",
            "    0.999182739457339,\n",
            "  f1_18: \n",
            "    0.4997956013408552,\n",
            "  accuracy_19: \n",
            "    0.9980385746976136,\n",
            "  f1_19: \n",
            "    0.33300610820244325,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9343856535749311,\n",
            "  f1: \n",
            "    0.613389068684091,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6708074534161491,\n",
            "  f1: \n",
            "    0.6707566462167689,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5] Finished epoch.\n",
            "[6] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n",
            "[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[########################################################################] 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:33s.\n",
            "[6] Validation results:\n",
            "[6] Preconditions:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9906044225470508,\n",
            "  f1: \n",
            "    0.19138883973750867,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9872974361369262,\n",
            "  f1_1: \n",
            "    0.616386607527217,\n",
            "  accuracy_2: \n",
            "    0.9988791855414935,\n",
            "  f1_2: \n",
            "    0.33314642617946205,\n",
            "  accuracy_3: \n",
            "    0.9985989819268668,\n",
            "  f1_3: \n",
            "    0.3330996666355111,\n",
            "  accuracy_4: \n",
            "    0.9996964460841545,\n",
            "  f1_4: \n",
            "    0.3332827333341118,\n",
            "  accuracy_5: \n",
            "    0.9760192406482043,\n",
            "  f1_5: \n",
            "    0.10978992325027974,\n",
            "  accuracy_6: \n",
            "    0.9723999439592771,\n",
            "  f1_6: \n",
            "    0.6014158695370263,\n",
            "  accuracy_7: \n",
            "    0.9982370522579741,\n",
            "  f1_7: \n",
            "    0.3330392494824319,\n",
            "  accuracy_8: \n",
            "    0.9921075981880166,\n",
            "  f1_8: \n",
            "    0.33201272163224477,\n",
            "  accuracy_9: \n",
            "    0.9741161910988652,\n",
            "  f1_9: \n",
            "    0.6052023363919096,\n",
            "  accuracy_10: \n",
            "    0.9950614112922057,\n",
            "  f1_10: \n",
            "    0.33250819771263823,\n",
            "  accuracy_11: \n",
            "    0.997151263251296,\n",
            "  f1_11: \n",
            "    0.3328578666354885,\n",
            "  accuracy_12: \n",
            "    0.992352776350815,\n",
            "  f1_12: \n",
            "    0.33205390401740803,\n",
            "  accuracy_13: \n",
            "    0.9977817213842058,\n",
            "  f1_13: \n",
            "    0.3329632097120438,\n",
            "  accuracy_14: \n",
            "    0.9946761313220941,\n",
            "  f1_14: \n",
            "    0.3324436536180308,\n",
            "  accuracy_15: \n",
            "    0.9935319665623686,\n",
            "  f1_15: \n",
            "    0.33225183016105414,\n",
            "  accuracy_16: \n",
            "    0.9929131835800682,\n",
            "  f1_16: \n",
            "    0.332147997133322,\n",
            "  accuracy_17: \n",
            "    0.9608532200065381,\n",
            "  f1_17: \n",
            "    0.5524824074040516,\n",
            "  accuracy_18: \n",
            "    0.9994045673189185,\n",
            "  f1_18: \n",
            "    0.33323406499934793,\n",
            "  accuracy_19: \n",
            "    0.9974548171671415,\n",
            "  f1_19: \n",
            "    0.33290859567702796,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Effects:\n",
            "{\n",
            "  accuracy: \n",
            "    0.9901164012515762,\n",
            "  f1: \n",
            "    0.1888686626200463,\n",
            "  accuracy_0: \n",
            "    0.9935553168635876,\n",
            "  f1_0: \n",
            "    0.3322557471264368,\n",
            "  accuracy_1: \n",
            "    0.9877644421613039,\n",
            "  f1_1: \n",
            "    0.6178875301557698,\n",
            "  accuracy_2: \n",
            "    0.9982020268061458,\n",
            "  f1_2: \n",
            "    0.33303340149965915,\n",
            "  accuracy_3: \n",
            "    0.9982954280110213,\n",
            "  f1_3: \n",
            "    0.3330489956648243,\n",
            "  accuracy_4: \n",
            "    0.9990659879512446,\n",
            "  f1_4: \n",
            "    0.3331775919263655,\n",
            "  accuracy_5: \n",
            "    0.9755989352262644,\n",
            "  f1_5: \n",
            "    0.10975950948288432,\n",
            "  accuracy_6: \n",
            "    0.9731121281464531,\n",
            "  f1_6: \n",
            "    0.6022795953640434,\n",
            "  accuracy_7: \n",
            "    0.9966725820763088,\n",
            "  f1_7: \n",
            "    0.3327778394993149,\n",
            "  accuracy_8: \n",
            "    0.99203754728436,\n",
            "  f1_8: \n",
            "    0.332000953374516,\n",
            "  accuracy_9: \n",
            "    0.9724116191098865,\n",
            "  f1_9: \n",
            "    0.6004386196437715,\n",
            "  accuracy_10: \n",
            "    0.9949329846355018,\n",
            "  f1_10: \n",
            "    0.3324866857845145,\n",
            "  accuracy_11: \n",
            "    0.9962989772568066,\n",
            "  f1_11: \n",
            "    0.33271535262914725,\n",
            "  accuracy_12: \n",
            "    0.9960070984915705,\n",
            "  f1_12: \n",
            "    0.3326665184855894,\n",
            "  accuracy_13: \n",
            "    0.9961472002988838,\n",
            "  f1_13: \n",
            "    0.332689960656786,\n",
            "  accuracy_14: \n",
            "    0.9944776537617335,\n",
            "  f1_14: \n",
            "    0.332410393898063,\n",
            "  accuracy_15: \n",
            "    0.9883365245411666,\n",
            "  f1_15: \n",
            "    0.3313780178699001,\n",
            "  accuracy_16: \n",
            "    0.9929482090318965,\n",
            "  f1_16: \n",
            "    0.33215387619605546,\n",
            "  accuracy_17: \n",
            "    0.959242049222435,\n",
            "  f1_17: \n",
            "    0.5472455753409601,\n",
            "  accuracy_18: \n",
            "    0.999182739457339,\n",
            "  f1_18: \n",
            "    0.4997956013408552,\n",
            "  accuracy_19: \n",
            "    0.9980385746976136,\n",
            "  f1_19: \n",
            "    0.33300610820244325,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Conflicts:\n",
            "{\n",
            "  accuracy: \n",
            "    0.909365805818895,\n",
            "  f1: \n",
            "    0.6050347323249877,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Stories:\n",
            "{\n",
            "  accuracy: \n",
            "    0.7267080745341615,\n",
            "  f1: \n",
            "    0.7265392781316349,\n",
            "  verifiability: \n",
            "    0.0,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Saving model checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6] Finished epoch.\n",
            "[7] Beginning epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[################################                                        ]  44%"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from www.model.train import train_epoch_tiered\n",
        "from www.model.eval import evaluate_tiered, save_results, save_preds, add_entity_attribute_labels\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from www.utils import print_dict, get_model_dir\n",
        "from www.model.transformers_ext import TieredModelPipeline\n",
        "from www.dataset.ann import att_to_num_classes\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "seed_val = 22 # Save random seed for reproducibility\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "epochs = 100\n",
        "# We'll keep the validation data here with a constant eval batch size\n",
        "dev_sampler = SequentialSampler(tiered_tensor_dataset['dev'])\n",
        "dev_dataloader = DataLoader(tiered_tensor_dataset['dev'], sampler=dev_sampler, batch_size=eval_batch_size)\n",
        "dev_dataset_name = subtask + '_%s_dev'\n",
        "dev_ids = [ex['example_id'] for ex in tiered_dataset['dev']]\n",
        "\n",
        "all_losses = []\n",
        "param_combos = []\n",
        "combo_names = []\n",
        "all_val_objs = []\n",
        "output_dirs = []\n",
        "best_obj = 0.0\n",
        "best_model = '<none>'\n",
        "best_dir = ''\n",
        "best_obj2 = 0.0\n",
        "best_model2 = '<none>'\n",
        "best_dir2 = ''\n",
        "batch_sizes = [4]\n",
        "print('Beginning grid search for the %s sub-task over %s parameter combination(s)!' % (subtask, str(len(batch_sizes) * len(learning_rates))))\n",
        "for bs in batch_sizes:\n",
        "  for lr in learning_rates:\n",
        "    print('\\nTRAINING MODEL: bs=%s, lr=%s' % (str(bs), str(lr)))\n",
        "\n",
        "    loss_values = []\n",
        "    obj_values = []\n",
        "\n",
        "    # Set up training dataset with new batch size\n",
        "    train_sampler = RandomSampler(tiered_tensor_dataset['train'])\n",
        "    train_dataloader = DataLoader(tiered_tensor_dataset['train'], sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "    # Set up model\n",
        "    config = config_class.from_pretrained(model_name,\n",
        "                                          cache_dir=os.path.join(DRIVE_PATH, 'cache'))    \n",
        "    emb = emb_class.from_pretrained(model_name,\n",
        "                                          config=config,\n",
        "                                          cache_dir=os.path.join(DRIVE_PATH, 'cache'))    \n",
        "    if torch.cuda.is_available():\n",
        "      emb.cuda()\n",
        "    device = emb.device\n",
        "    max_story_length = max([len(ex['stories'][0]['sentences']) for p in tiered_dataset for ex in tiered_dataset[p]])\n",
        "    model = TieredModelPipeline(emb, max_story_length, len(att_to_num_classes), num_state_labels,\n",
        "                                config_class, model_name, device, \n",
        "                                ablation=ablation, loss_weights=loss_weights).to(device)\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps = total_steps)\n",
        "\n",
        "    train_lc_data = []\n",
        "    val_lc_data = []\n",
        "    for epoch in range(epochs):\n",
        "      # Train the model for one epoch\n",
        "      print('[%s] Beginning epoch...' % str(epoch))\n",
        "\n",
        "      epoch_loss, _ = train_epoch_tiered(model, optimizer, train_dataloader, device, seg_mode=False, \n",
        "                                         build_learning_curves=generate_learning_curve, val_dataloader=dev_dataloader, \n",
        "                                         train_lc_data=train_lc_data, val_lc_data=val_lc_data)\n",
        "      \n",
        "      # Save loss\n",
        "      loss_values.append(epoch_loss)\n",
        "\n",
        "      # Validate on dev set\n",
        "      validation_results = evaluate_tiered(model, dev_dataloader, device, [(accuracy_score, 'accuracy'), (f1_score, 'f1')], seg_mode=False, return_explanations=True)\n",
        "      metr_attr, all_pred_atts, all_atts, \\\n",
        "      metr_prec, all_pred_prec, all_prec, \\\n",
        "      metr_eff, all_pred_eff, all_eff, \\\n",
        "      metr_conflicts, all_pred_conflicts, all_conflicts, \\\n",
        "      metr_stories, all_pred_stories, all_stories, explanations = validation_results[:16]\n",
        "      explanations = add_entity_attribute_labels(explanations, tiered_dataset['dev'], list(att_to_num_classes.keys()))\n",
        "\n",
        "      print('[%s] Validation results:' % str(epoch))\n",
        "      print('[%s] Preconditions:' % str(epoch))\n",
        "      print_dict(metr_prec)\n",
        "      print('[%s] Effects:' % str(epoch))\n",
        "      print_dict(metr_eff)\n",
        "      print('[%s] Conflicts:' % str(epoch))\n",
        "      print_dict(metr_conflicts)\n",
        "      print('[%s] Stories:' % str(epoch))\n",
        "      print_dict(metr_stories)\n",
        "\n",
        "      # Save accuracy - want to maximize verifiability of tiered predictions\n",
        "      ver = metr_stories['verifiability']\n",
        "      acc = metr_stories['accuracy']\n",
        "      obj_values.append(ver)\n",
        "      \n",
        "      # Save model checkpoint\n",
        "      print('[%s] Saving model checkpoint...' % str(epoch))\n",
        "      model_param_str = get_model_dir(model_name.replace('/', '-'), subtask, bs, lr, epoch) + '_' +  '-'.join([str(lw) for lw in loss_weights]) +  '_tiered_pipeline_lc'\n",
        "      if train_spans:\n",
        "        model_param_str += 'spans'\n",
        "      if len(model.ablation) > 0:\n",
        "        model_param_str += '_ablate_'\n",
        "        model_param_str += '_'.join(model.ablation)\n",
        "      output_dir = os.path.join(DRIVE_PATH, 'saved_models', model_param_str)\n",
        "      output_dirs.append(output_dir)\n",
        "      if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "      save_results(metr_attr, output_dir, dev_dataset_name % 'attributes')\n",
        "      save_results(metr_prec, output_dir, dev_dataset_name % 'preconditions')\n",
        "      save_results(metr_eff, output_dir, dev_dataset_name % 'effects')\n",
        "      save_results(metr_conflicts, output_dir, dev_dataset_name % 'conflicts')\n",
        "      save_results(metr_stories, output_dir, dev_dataset_name % 'stories')\n",
        "      save_results(explanations, output_dir, dev_dataset_name % 'explanations')\n",
        "\n",
        "      # Just save story preds\n",
        "      save_preds(dev_ids, all_stories, all_pred_stories, output_dir, dev_dataset_name % 'stories')\n",
        "\n",
        "      emb = emb.module if hasattr(emb, 'module') else emb\n",
        "      emb.save_pretrained(output_dir)\n",
        "      torch.save(model, os.path.join(output_dir, 'classifiers.pth'))\n",
        "      tokenizer.save_vocabulary(output_dir)\n",
        "\n",
        "      if ver > best_obj:\n",
        "        best_obj = ver\n",
        "        best_model = model_param_str\n",
        "        best_dir = output_dir\n",
        "      if acc > best_obj2:\n",
        "        best_obj2 = acc\n",
        "        best_model2 = model_param_str\n",
        "        best_dir2 = output_dir        \n",
        "\n",
        "      for od in output_dirs:\n",
        "        if od != best_dir and od != best_dir2 and os.path.exists(od):\n",
        "          shutil.rmtree(od)\n",
        "\n",
        "      print('[%s] Finished epoch.' % str(epoch))\n",
        "\n",
        "    all_losses.append(loss_values)\n",
        "    all_val_objs.append(obj_values)\n",
        "    param_combos.append((bs, lr))\n",
        "    combo_names.append('bs=%s, lr=%s' % (str(bs), str(lr)))\n",
        "\n",
        "print('Finished grid search! :)')\n",
        "print('Best validation *verifiability* %s from model %s.' % (str(best_obj), best_model))\n",
        "print('Best validation *accuracy* %s from model %s.' % (str(best_obj2), best_model2))\n",
        "\n",
        "if generate_learning_curve:\n",
        "  print('Saving learning curve data...')\n",
        "  train_lc_data = [subrecord for record in train_lc_data for subrecord in record] # flatten\n",
        "  val_lc_data = [subrecord for record in val_lc_data for subrecord in record] # flatten\n",
        "\n",
        "  train_lc_data = pd.DataFrame(train_lc_data)\n",
        "  print(os.path.join(best_dir if best_dir != '<none>' else best_dir2, 'learning_curve_data_train.csv'))\n",
        "  train_lc_data.to_csv(os.path.join(best_dir if best_dir != '' else best_dir2, 'learning_curve_data_train.csv'), index=False)\n",
        "  val_lc_data = pd.DataFrame(val_lc_data)\n",
        "  val_lc_data.to_csv(os.path.join(best_dir if best_dir != '' else best_dir2, 'learning_curve_data_val.csv'), index=False)\n",
        "  print('Learning curve data saved. %s rows saved for training, %s rows saved for validation.' % (str(len(train_lc_data.index)), str(len(val_lc_data.index))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_jhT4gSBdq5"
      },
      "source": [
        "Delete all non-best model checkpoints:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWFmGRhznl2T"
      },
      "source": [
        "### Test Models\n",
        "\n",
        "Evaluate accuracy, consistency, and verifiability on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbvpm9irn3qL"
      },
      "source": [
        "#### Load the Trained Model\n",
        "\n",
        "Load the trained model we want to probe and select the appropriate dataset. Paths to the pre-trained models presented in the paper are already provided (download links are found in GitHub repo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM_lYqw9n3qM"
      },
      "outputs": [],
      "source": [
        "from www.model.transformers_ext import TieredModelPipeline\n",
        "from www.dataset.ann import att_to_num_classes, att_to_idx, att_types\n",
        "eval_model_dir = \"xlnet-base-cased_cloze_4_1e-05_16_0.0-0.4-0.4-0.2-0.0_tiered_pipeline_lc_ablate_attributes_states-logits\"\n",
        "probe_model = eval_model_dir\n",
        "probe_model = os.path.join(DRIVE_PATH, 'saved_models', probe_model)\n",
        "\n",
        "ablation = ['attributes', 'states-logits']\n",
        "\n",
        "if 'cloze' in probe_model:\n",
        "  subtask = 'cloze'\n",
        "elif 'order' in probe_model:\n",
        "  subtask = 'order'\n",
        "  \n",
        "if subtask == 'cloze':\n",
        "  subtask_dataset = cloze_dataset_2s\n",
        "elif subtask == 'order':\n",
        "  subtask_dataset = order_dataset_2s\n",
        "\n",
        "# Load the model\n",
        "model = None\n",
        "# model = torch.load(os.path.join(probe_model, 'classifiers.pth'), map_location=torch.device('cpu'))\n",
        "model = torch.load(os.path.join(probe_model, 'classifiers.pth'))\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "device = model.embedding.device\n",
        "\n",
        "for layer in model.precondition_classifiers:\n",
        "  layer.eval()\n",
        "for layer in model.effect_classifiers:\n",
        "  layer.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfXiCTA9KPjG"
      },
      "source": [
        "#### Test the Model\n",
        "\n",
        "Run inference on the testing set of TRIP. Can simply edit the top-level `for` loop if you want to run inference on other partitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQX4bIxcKWlf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from www.model.eval import evaluate_tiered, save_results, save_preds, list_comparison, add_entity_attribute_labels\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "metrics = [(accuracy_score, 'accuracy'), (precision_score, 'precision'), (recall_score, 'recall'), (f1_score, 'f1')]\n",
        "import numpy as np\n",
        "from www.utils import print_dict\n",
        "\n",
        "print('\\n Testing model: %s.' % probe_model)\n",
        "\n",
        "# May alter this depending on which partition(s) you want to run inference on\n",
        "for p in tiered_dataset:\n",
        "  if p != 'test':\n",
        "    continue\n",
        "\n",
        "  p_dataset = tiered_dataset[p]\n",
        "  p_tensor_dataset = tiered_tensor_dataset[p]\n",
        "  p_sampler = SequentialSampler(p_tensor_dataset)\n",
        "  p_dataloader = DataLoader(p_tensor_dataset, sampler=p_sampler, batch_size=16)\n",
        "  dev_dataset_name = subtask + '_%s_' + p\n",
        "  p_ids = [ex['example_id'] for ex in tiered_dataset[p]]\n",
        "\n",
        "  # Get preds and metrics on this partition\n",
        "  metr_attr, all_pred_atts, all_atts, \\\n",
        "  metr_prec, all_pred_prec, all_prec, \\\n",
        "  metr_eff, all_pred_eff, all_eff, \\\n",
        "  metr_conflicts, all_pred_conflicts, all_conflicts, \\\n",
        "  metr_stories, all_pred_stories, all_stories, explanations = evaluate_tiered(model, p_dataloader, device, [(accuracy_score, 'accuracy'), (f1_score, 'f1')], seg_mode=False, return_explanations=True)\n",
        "  explanations = add_entity_attribute_labels(explanations, tiered_dataset[p], list(att_to_num_classes.keys()))\n",
        "\n",
        "  save_results(metr_attr, probe_model, dev_dataset_name % 'attributes')\n",
        "  save_results(metr_prec, probe_model, dev_dataset_name % 'preconditions')\n",
        "  save_results(metr_eff, probe_model, dev_dataset_name % 'effects')\n",
        "  save_results(metr_conflicts, probe_model, dev_dataset_name % 'conflicts')\n",
        "  save_results(metr_stories, probe_model, dev_dataset_name % 'stories')\n",
        "  save_results(explanations, probe_model, dev_dataset_name % 'explanations')\n",
        "\n",
        "  print('\\nPARTITION: %s' % p)\n",
        "  print('Stories:')\n",
        "  print_dict(metr_stories)\n",
        "  print('Conflicts:')\n",
        "  print_dict(metr_conflicts)\n",
        "  print('Preconditions:')\n",
        "  print_dict(metr_prec)\n",
        "  print('Effects:')\n",
        "  print_dict(metr_eff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON1UAnbc8OOE"
      },
      "source": [
        "#### Add Consistency Metric to Model Results\n",
        "The intermediate conistency metric isn't included in the originally calculated metrics. This block adds the consistency metric to pre-existing model directory based on the tiered predictions. Generates a new `results_cloze_stories_final_[partition].json` file that includes the consistency metric.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1obFel58pd-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "model_directories = [eval_model_dir]\n",
        "\n",
        "partitions = ['dev', 'test']\n",
        "expl_fname = 'results_cloze_explanations_%s.json'\n",
        "endtask_fname = 'results_cloze_stories_%s.json'\n",
        "endtask_fname_new = 'results_cloze_stories_final_%s.json'\n",
        "for md in model_directories:\n",
        "  for p in partitions:\n",
        "    explanations = json.load(open(os.path.join(DRIVE_PATH, 'saved_models', md, expl_fname % p), 'r'))\n",
        "    endtask_results = json.load(open(os.path.join(DRIVE_PATH, 'saved_models', md, endtask_fname % p), 'r'))\n",
        "\n",
        "    consistent_preds = 0\n",
        "    verifiable_preds = 0\n",
        "    total = 0\n",
        "    for expl in explanations:\n",
        "      if expl['valid_explanation']:\n",
        "        verifiable_preds += 1\n",
        "      if expl['story_pred'] == expl['story_label']:\n",
        "        if len(expl['conflict_pred']) == len(expl['conflict_label']) and expl['conflict_pred'][0] == expl['conflict_label'][0] and expl['conflict_pred'][1] == expl['conflict_label'][1]:\n",
        "          expl['consistent'] = True\n",
        "          consistent_preds += 1\n",
        "        else:\n",
        "          expl['consistent'] = False\n",
        "      total += 1\n",
        "\n",
        "    endtask_results['consistency'] = float(consistent_preds) / total\n",
        "    print('Found %s consistent preds in %s (versus %s verifiable)' % (str(consistent_preds), p, str(verifiable_preds)))\n",
        "    json.dump(explanations, open(os.path.join(DRIVE_PATH, 'saved_models', md, (expl_fname % p).replace('explanations', 'explanations_consistency')), 'w'))\n",
        "    json.dump(endtask_results, open(os.path.join(DRIVE_PATH, 'saved_models', md, endtask_fname_new % p), 'w'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "qqvj34KhLL0k",
        "v7VlN2jUwvcC",
        "-fQ6wXQIBdq1",
        "aWFmGRhznl2T",
        "Rbvpm9irn3qL",
        "RfXiCTA9KPjG",
        "ON1UAnbc8OOE"
      ],
      "machine_shape": "hm",
      "name": "Verifiable-Coherent-NLU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d999932e6a049dc99989e043e81e57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec038468df534ed9871bdb8674ba1318",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_781444ccbdc343148ace0a165e3f20f5",
              "IPY_MODEL_c7062e9e76d54f328c27c700ddb5e8bc",
              "IPY_MODEL_0d097e0ec7ef413ab12bb5b721a4103c"
            ]
          }
        },
        "ec038468df534ed9871bdb8674ba1318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "781444ccbdc343148ace0a165e3f20f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_816fd3679da94aabb2b9d95a1356665e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7f29ecd7db34b4cb430cb68a5282783"
          }
        },
        "c7062e9e76d54f328c27c700ddb5e8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13b7b584a5144922a3708aa9da75c803",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ec8bd329a6d4e40b3828bbda2407dc4"
          }
        },
        "0d097e0ec7ef413ab12bb5b721a4103c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2c539694b94446697ee00944bed0f1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760/760 [00:00&lt;00:00, 7.73kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1576720784c34573a14d4c76a9778388"
          }
        },
        "816fd3679da94aabb2b9d95a1356665e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7f29ecd7db34b4cb430cb68a5282783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13b7b584a5144922a3708aa9da75c803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ec8bd329a6d4e40b3828bbda2407dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2c539694b94446697ee00944bed0f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1576720784c34573a14d4c76a9778388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}